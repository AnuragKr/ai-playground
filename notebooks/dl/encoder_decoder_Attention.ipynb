{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-07T07:05:52.300707Z",
          "iopub.status.busy": "2024-05-07T07:05:52.300025Z",
          "iopub.status.idle": "2024-05-07T07:06:08.733764Z",
          "shell.execute_reply": "2024-05-07T07:06:08.732776Z",
          "shell.execute_reply.started": "2024-05-07T07:05:52.300660Z"
        },
        "id": "Yvi9zQt4GxyL",
        "outputId": "54441736-433a-407b-f26c-8a7ce59dac47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-07T07:06:17.294211Z",
          "iopub.status.busy": "2024-05-07T07:06:17.293801Z",
          "iopub.status.idle": "2024-05-07T07:06:18.116684Z",
          "shell.execute_reply": "2024-05-07T07:06:18.115878Z",
          "shell.execute_reply.started": "2024-05-07T07:06:17.294170Z"
        },
        "id": "UsM1GkQrGxyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d709ab4b-12a6-4319-c28e-b4a3f3a97887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d5eczMIC9S8j"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Dataset/news_summary.csv\", encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-07T07:06:52.558954Z",
          "iopub.status.busy": "2024-05-07T07:06:52.558049Z",
          "iopub.status.idle": "2024-05-07T07:06:52.564408Z",
          "shell.execute_reply": "2024-05-07T07:06:52.563502Z",
          "shell.execute_reply.started": "2024-05-07T07:06:52.558911Z"
        },
        "id": "UM9Q9mdHGxyN"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(df, col):\n",
        "    # converting language data in data frame to lower case and then storing in sentence variable\n",
        "    sentence = df[col].str.lower()\n",
        "    sentence = sentence.str.replace('[^0-9A-Za-z\\s]+', '', regex=True)\n",
        "    sentence = sentence.str.normalize('NFD')\n",
        "    #encoding the string in sentence in UTF-8 format and ignoring errors if any\n",
        "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-07T07:06:55.439214Z",
          "iopub.status.busy": "2024-05-07T07:06:55.438839Z",
          "iopub.status.idle": "2024-05-07T07:06:58.168161Z",
          "shell.execute_reply": "2024-05-07T07:06:58.167340Z",
          "shell.execute_reply.started": "2024-05-07T07:06:55.439183Z"
        },
        "id": "ygm5yIeVGxyO"
      },
      "outputs": [],
      "source": [
        "dataset['headlines'] = preprocess_text(dataset, 'headlines')\n",
        "dataset['text'] = preprocess_text(dataset, 'text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:12.122293Z",
          "iopub.status.busy": "2024-05-06T17:29:12.121982Z",
          "iopub.status.idle": "2024-05-06T17:29:12.130034Z",
          "shell.execute_reply": "2024-05-06T17:29:12.129104Z",
          "shell.execute_reply.started": "2024-05-06T17:29:12.122266Z"
        },
        "id": "_SEWkdhtGxyO"
      },
      "outputs": [],
      "source": [
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "# make the token 1 and 2 ,0 is already reserved for the [pad]\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0:'PAD',1: \"SOS\", 2: \"EOS\"}\n",
        "        self.n_words = 3  # Count SOS and EOS\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:12.131476Z",
          "iopub.status.busy": "2024-05-06T17:29:12.131197Z",
          "iopub.status.idle": "2024-05-06T17:29:16.129100Z",
          "shell.execute_reply": "2024-05-06T17:29:16.128076Z",
          "shell.execute_reply.started": "2024-05-06T17:29:12.131445Z"
        },
        "id": "qCjmxVR_GxyO"
      },
      "outputs": [],
      "source": [
        "vocab = Vocab()\n",
        "\n",
        "_ = dataset.text.apply(lambda x: vocab.add_sentence(x))\n",
        "_ = dataset.headlines.apply(lambda x: vocab.add_sentence(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:16.130868Z",
          "iopub.status.busy": "2024-05-06T17:29:16.130485Z",
          "iopub.status.idle": "2024-05-06T17:29:16.137824Z",
          "shell.execute_reply": "2024-05-06T17:29:16.136896Z",
          "shell.execute_reply.started": "2024-05-06T17:29:16.130830Z"
        },
        "id": "ffEmuuUIGxyO",
        "outputId": "4fc1954f-250a-4e39-fb8a-fdc86244121a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120908"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vocab.n_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:16.139610Z",
          "iopub.status.busy": "2024-05-06T17:29:16.139162Z",
          "iopub.status.idle": "2024-05-06T17:29:17.758747Z",
          "shell.execute_reply": "2024-05-06T17:29:17.757708Z",
          "shell.execute_reply.started": "2024-05-06T17:29:16.139576Z"
        },
        "id": "UzVAyx5tGxyP"
      },
      "outputs": [],
      "source": [
        "dataset['text_length'] = dataset.text.str.split(' ').apply(lambda x: len(x))\n",
        "dataset['headlines_length'] = dataset.headlines.str.split(' ').apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.760907Z",
          "iopub.status.busy": "2024-05-06T17:29:17.760598Z",
          "iopub.status.idle": "2024-05-06T17:29:17.768237Z",
          "shell.execute_reply": "2024-05-06T17:29:17.767190Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.760879Z"
        },
        "id": "8QVdQaRKGxyP",
        "outputId": "707ce0bb-7e5e-41c6-80ee-c854f29849d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset.headlines_length.max(), dataset.text_length.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.770235Z",
          "iopub.status.busy": "2024-05-06T17:29:17.769857Z",
          "iopub.status.idle": "2024-05-06T17:29:17.778562Z",
          "shell.execute_reply": "2024-05-06T17:29:17.777573Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.770199Z"
        },
        "id": "p7xuCVsyGxyP"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH_INPUT = 100\n",
        "MAX_LENGTH_TARGET = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.783390Z",
          "iopub.status.busy": "2024-05-06T17:29:17.783088Z",
          "iopub.status.idle": "2024-05-06T17:29:17.789035Z",
          "shell.execute_reply": "2024-05-06T17:29:17.788113Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.783365Z"
        },
        "id": "ksgEhet8GxyQ"
      },
      "outputs": [],
      "source": [
        "def indexes_from_sentence(vocab, sentence):\n",
        "    return [vocab.word2index[word] for word in sentence.split(' ')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.790530Z",
          "iopub.status.busy": "2024-05-06T17:29:17.790234Z",
          "iopub.status.idle": "2024-05-06T17:29:17.799262Z",
          "shell.execute_reply": "2024-05-06T17:29:17.798271Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.790504Z"
        },
        "id": "RIgCPw5IGxyQ"
      },
      "outputs": [],
      "source": [
        "def tensor_from_sentence(vocab, sentence):\n",
        "    indexes = indexes_from_sentence(vocab, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.800603Z",
          "iopub.status.busy": "2024-05-06T17:29:17.800305Z",
          "iopub.status.idle": "2024-05-06T17:29:17.809542Z",
          "shell.execute_reply": "2024-05-06T17:29:17.808606Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.800579Z"
        },
        "id": "7H0L1a2aGxyQ"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(dataset, batch_size):\n",
        "    n = dataset.shape[0]\n",
        "    input_ids = np.zeros((n, MAX_LENGTH_INPUT), dtype=np.int64)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH_TARGET), dtype=np.int64)\n",
        "\n",
        "    for idx in range(n):\n",
        "        inp_ids = indexes_from_sentence(vocab, dataset.text.iloc[idx])\n",
        "        tgt_ids = indexes_from_sentence(vocab, dataset.headlines.iloc[idx])\n",
        "\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.810999Z",
          "iopub.status.busy": "2024-05-06T17:29:17.810673Z",
          "iopub.status.idle": "2024-05-06T17:29:17.820837Z",
          "shell.execute_reply": "2024-05-06T17:29:17.819957Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.810953Z"
        },
        "id": "HoGwe_qPGxyS"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # Update to use LSTM\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        return output, (hidden, cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.822506Z",
          "iopub.status.busy": "2024-05-06T17:29:17.822218Z",
          "iopub.status.idle": "2024-05-06T17:29:17.836770Z",
          "shell.execute_reply": "2024-05-06T17:29:17.835890Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.822482Z"
        },
        "id": "W2uGqKVoGxyS",
        "outputId": "4a45b966-772f-4251-a280-471a285f5248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(100, 64)\n",
            "  (lstm): LSTM(64, 64, batch_first=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "enc = Encoder(100, 64)\n",
        "print(enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.838485Z",
          "iopub.status.busy": "2024-05-06T17:29:17.837755Z",
          "iopub.status.idle": "2024-05-06T17:29:17.844488Z",
          "shell.execute_reply": "2024-05-06T17:29:17.843486Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.838459Z"
        },
        "id": "YKxjGnTHGxyS"
      },
      "outputs": [],
      "source": [
        "x = torch.randint(1, 100, (1, 61))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.846014Z",
          "iopub.status.busy": "2024-05-06T17:29:17.845430Z",
          "iopub.status.idle": "2024-05-06T17:29:17.920451Z",
          "shell.execute_reply": "2024-05-06T17:29:17.919514Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.845970Z"
        },
        "id": "H9WO7nYXGxyS"
      },
      "outputs": [],
      "source": [
        "enc_outputs, enc_hidden = enc.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.921752Z",
          "iopub.status.busy": "2024-05-06T17:29:17.921485Z",
          "iopub.status.idle": "2024-05-06T17:29:17.927654Z",
          "shell.execute_reply": "2024-05-06T17:29:17.926666Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.921728Z"
        },
        "id": "qMQ_FSEqGxyT",
        "outputId": "9ee418e1-ee9b-4163-916a-559f91172305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_outputs_shape: torch.Size([1, 61, 64])\n",
            "enc_hidden_h_shape: torch.Size([1, 1, 64])\n",
            "enc_hidden_c_shape: torch.Size([1, 1, 64])\n"
          ]
        }
      ],
      "source": [
        "enc_hidden_h_shape = enc_hidden[0].shape\n",
        "enc_hidden_c_shape = enc_hidden[1].shape\n",
        "enc_outputs_shape = enc_outputs.shape\n",
        "\n",
        "print(\"enc_outputs_shape:\", enc_outputs_shape)\n",
        "print(\"enc_hidden_h_shape:\", enc_hidden_h_shape)\n",
        "print(\"enc_hidden_c_shape:\", enc_hidden_c_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.938190Z",
          "iopub.status.busy": "2024-05-06T17:29:17.937902Z",
          "iopub.status.idle": "2024-05-06T17:29:17.950761Z",
          "shell.execute_reply": "2024-05-06T17:29:17.949839Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.938162Z"
        },
        "id": "MEAF-Fyn_D8W"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "        attn_energies = torch.zeros(batch_size, seq_len, device=encoder_outputs.device)\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            attn_energies[:, i] = self.score(hidden, encoder_outputs[:, i, :])\n",
        "\n",
        "        #this is the alpha\n",
        "        attn_weights = F.softmax(attn_energies, dim=1)\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # Compute the context vector\n",
        "        return context, attn_weights\n",
        "\n",
        "    def score(self, hidden, encoder_output):\n",
        "        if hidden.dim() == 1:\n",
        "            hidden = hidden.unsqueeze(0)\n",
        "        if encoder_output.dim() == 1:\n",
        "            encoder_output = encoder_output.unsqueeze(0)\n",
        "\n",
        "        combined = torch.cat((hidden, encoder_output), dim=1)\n",
        "        energy = self.attention(combined)\n",
        "        return energy.squeeze(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iVf3Bf0rppK"
      },
      "source": [
        "**Explanation-**\n",
        "\n",
        "1. **Initialization**:\n",
        "   - The class `BahdanauAttention` is created as a subclass of `nn.Module`.\n",
        "   - It initializes a linear layer (`self.attention`) with input size `hidden_size * 2` and output size 1. This linear layer is used to compute attention scores.\n",
        "\n",
        "2. **Forward Pass**:\n",
        "   - During the forward pass, the method takes two inputs: `hidden` state from the decoder and `encoder_outputs` from the encoder.\n",
        "   - It iterates through the sequence length of `encoder_outputs` to calculate attention scores for each time step.\n",
        "\n",
        "3. **Score Calculation**:\n",
        "   - The `score` method concatenates the `hidden` state and the `encoder_output` for each time step.\n",
        "   - The concatenated tensor is passed through the linear layer (`self.attention`) to compute attention energies.\n",
        "\n",
        "4. **Attention Weights**:\n",
        "   - Softmax is applied to the computed attention energies across the sequence dimension (`dim=1`) to obtain attention weights.\n",
        "   - Softmax ensures that the attention weights sum up to 1, representing the importance of each encoder output for the current decoding step.\n",
        "\n",
        "5. **Context Vector**:\n",
        "   - Using the computed attention weights, a context vector is calculated as the weighted sum of encoder outputs.\n",
        "   - This context vector captures relevant information from the encoder outputs based on their importance determined by the attention weights.\n",
        "\n",
        "6. **Return**:\n",
        "   - Finally, the method returns the context vector and attention weights, providing valuable information for the decoder to generate the next output word.\n",
        "\n",
        "Overall, the Bahdanau Attention mechanism enables the decoder to focus on different parts of the input sequence dynamically during the decoding process, enhancing the model's ability to generate accurate and contextually relevant outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.952170Z",
          "iopub.status.busy": "2024-05-06T17:29:17.951897Z",
          "iopub.status.idle": "2024-05-06T17:29:17.966642Z",
          "shell.execute_reply": "2024-05-06T17:29:17.965622Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.952144Z"
        },
        "id": "eu2fJ23Gw6vQ"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size).to(device)\n",
        "        self.lstm = nn.LSTM(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "\n",
        "        decoder_hidden, decoder_cell = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH_TARGET):\n",
        "            decoder_output, (decoder_hidden, decoder_cell), attn_weights = self.forward_step(\n",
        "                decoder_input, (decoder_hidden, decoder_cell), encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def forward_step(self, input, hidden_state, encoder_outputs):\n",
        "        hidden, cell = hidden_state\n",
        "        embedded = self.dropout(self.embedding(input))  # Shape: [batch_size, 1, hidden_size]\n",
        "\n",
        "        hidden_state_permuted = hidden.permute(1, 0, 2)[:, -1, :]  # Select only the last layer's hidden state, Shape: [batch_size, hidden_size]\n",
        "        context, attn_weights = self.attention(hidden_state_permuted, encoder_outputs)  # Context should be [batch_size, 1, hidden_size]\n",
        "\n",
        "        # Make sure context is not squeezed excessively\n",
        "        context = context.squeeze(1)  # Correct context shape if necessary. Shape should be [batch_size, hidden_size]\n",
        "        context = context.unsqueeze(1)  # Maintain the sequence length dimension for LSTM input\n",
        "\n",
        "        input_lstm = torch.cat((embedded, context), dim=2)  # Concatenate along the feature dimension\n",
        "        output, (hidden, cell) = self.lstm(input_lstm, (hidden, cell))\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, (hidden, cell), attn_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFduoKVttUTI"
      },
      "source": [
        "**Explanation-**\n",
        "Let's break down the `AttnDecoderRNN` class and its methods in chronological order:\n",
        "\n",
        "1. **Initialization**:\n",
        "   - The constructor initializes the decoder with an embedding layer (`self.embedding`), Bahdanau attention mechanism (`self.attention`), LSTM layer (`self.lstm`), linear layer for output (`self.out`), and dropout (`self.dropout`).\n",
        "\n",
        "2. **Forward Pass**:\n",
        "   - During the forward pass, it takes encoder outputs (`encoder_outputs`), encoder hidden states (`encoder_hidden`), and optional target tensor (`target_tensor`) as inputs.\n",
        "   - It initializes the decoder input with the start-of-sequence token (`SOS_token`).\n",
        "   - Decoder hidden and cell states are extracted from the encoder hidden states.\n",
        "   - It iterates over the maximum length of the target sequence.\n",
        "   \n",
        "3. **Forward Step**:\n",
        "   - Inside the loop, for each timestep:\n",
        "     - The `forward_step` method is called to compute the output, new hidden and cell states, and attention weights.\n",
        "     - In `forward_step`, the decoder input is embedded using the embedding layer, and dropout is applied.\n",
        "     - The previous hidden state is permuted to match the dimensions for attention calculation, and the context vector and attention weights are computed using the Bahdanau attention mechanism.\n",
        "     - The context vector is concatenated with the embedded input, and passed through the LSTM layer.\n",
        "     - The LSTM output is passed through the linear layer to obtain the output probabilities for the current timestep.\n",
        "   \n",
        "4. **Output Processing**:\n",
        "   - The outputs, hidden states, and attention weights for each timestep are collected and stored.\n",
        "   - If a target tensor is provided, the next input token is extracted from it; otherwise, the token with the highest probability is selected.\n",
        "   \n",
        "5. **Finalization**:\n",
        "   - The decoder outputs, which contain the log probabilities of output tokens for each timestep, are concatenated along the sequence dimension and processed using a softmax function.\n",
        "   - The attention weights are concatenated similarly.\n",
        "   - Finally, the decoder outputs, hidden states, and attention weights are returned as outputs of the forward pass.\n",
        "\n",
        "This comprehensive process enables the `AttnDecoderRNN` to decode input sequences with attention, allowing it to produce accurate and contextually relevant output sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.968045Z",
          "iopub.status.busy": "2024-05-06T17:29:17.967714Z",
          "iopub.status.idle": "2024-05-06T17:29:17.981089Z",
          "shell.execute_reply": "2024-05-06T17:29:17.980163Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.968021Z"
        },
        "id": "FC8Q9OpfGxyU",
        "outputId": "596f3f2a-88a7-49f1-d696-21cb6d06d4d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tgt_tensor = torch.randint(1, 100, (1, 20))\n",
        "tgt_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:17.982599Z",
          "iopub.status.busy": "2024-05-06T17:29:17.982318Z",
          "iopub.status.idle": "2024-05-06T17:29:18.123408Z",
          "shell.execute_reply": "2024-05-06T17:29:18.122375Z",
          "shell.execute_reply.started": "2024-05-06T17:29:17.982569Z"
        },
        "id": "eb4nOr4-GxyU"
      },
      "outputs": [],
      "source": [
        "dec = AttnDecoderRNN(64, 100).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:18.124798Z",
          "iopub.status.busy": "2024-05-06T17:29:18.124513Z",
          "iopub.status.idle": "2024-05-06T17:29:18.131002Z",
          "shell.execute_reply": "2024-05-06T17:29:18.130176Z",
          "shell.execute_reply.started": "2024-05-06T17:29:18.124772Z"
        },
        "id": "1IFBXfknGxyU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Move your models to the designated device\n",
        "encoder = enc.to(device)\n",
        "decoder = dec.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:18.132582Z",
          "iopub.status.busy": "2024-05-06T17:29:18.132296Z",
          "iopub.status.idle": "2024-05-06T17:29:18.142586Z",
          "shell.execute_reply": "2024-05-06T17:29:18.141704Z",
          "shell.execute_reply.started": "2024-05-06T17:29:18.132557Z"
        },
        "id": "dLDDKPqwGxyU",
        "outputId": "ca719592-64f8-4b00-e01d-749a8c1ddfb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 64]) torch.Size([1, 1, 64])\n"
          ]
        }
      ],
      "source": [
        "# When you load or create tensors, send them to the same device\n",
        "enc_outputs = enc_outputs.to(device)\n",
        "(h,c) = enc_hidden\n",
        "enc_hidden_gpu=h.to(device),c.to(device)\n",
        "tgt_tensor = tgt_tensor.to(device)\n",
        "print(h.shape,c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:29:18.144140Z",
          "iopub.status.busy": "2024-05-06T17:29:18.143759Z",
          "iopub.status.idle": "2024-05-06T17:29:18.657214Z",
          "shell.execute_reply": "2024-05-06T17:29:18.656375Z",
          "shell.execute_reply.started": "2024-05-06T17:29:18.144059Z"
        },
        "id": "oVUggMiOGxyU"
      },
      "outputs": [],
      "source": [
        "decoder_outputs, decoder_hidden, attentions = dec.forward(enc_outputs, enc_hidden_gpu, tgt_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:30:15.790606Z",
          "iopub.status.busy": "2024-05-06T17:30:15.790215Z",
          "iopub.status.idle": "2024-05-06T17:30:15.806391Z",
          "shell.execute_reply": "2024-05-06T17:30:15.805379Z",
          "shell.execute_reply.started": "2024-05-06T17:30:15.790577Z"
        },
        "id": "_DUYYWq4KU8j"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    total_loss = 0\n",
        "    for input_tensor, target_tensor in tqdm(dataloader):\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate_model(dataloader, encoder, decoder, criterion):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for input_tensor, target_tensor in tqdm(dataloader):\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            loss = criterion(\n",
        "                decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "                target_tensor.view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def train_model(train_dataloader, valid_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "                print_every=100, plot_every=100):\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        print(f\"Epoch: {epoch}/{n_epochs}\")\n",
        "        # Training\n",
        "        train_loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer,\n",
        "                                 decoder_optimizer, criterion)\n",
        "        print_loss_total += train_loss\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(f\"Train Loss: {round(print_loss_avg, 3)}\")\n",
        "\n",
        "        # Validation\n",
        "        print('Validation....')\n",
        "        valid_loss = evaluate_model(valid_dataloader, encoder, decoder, criterion)\n",
        "        valid_losses.append(valid_loss)\n",
        "        print(f\"Validation Loss: {round(valid_loss, 3)}\")\n",
        "\n",
        "        # Save the model if it has the best validation loss so far\n",
        "        if valid_loss < best_val_loss:\n",
        "            best_val_loss = valid_loss\n",
        "            torch.save(encoder.state_dict(), 'best_encoder.pth')\n",
        "            torch.save(decoder.state_dict(), 'best_decoder.pth')\n",
        "            print(f\"Saved Best Model at Epoch: {epoch}\")\n",
        "\n",
        "    return train_losses, valid_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-06T17:30:17.854957Z",
          "iopub.status.busy": "2024-05-06T17:30:17.854589Z",
          "iopub.status.idle": "2024-05-06T17:30:17.898567Z",
          "shell.execute_reply": "2024-05-06T17:30:17.897592Z",
          "shell.execute_reply.started": "2024-05-06T17:30:17.854928Z"
        },
        "id": "fwpqjwxBGxyW",
        "outputId": "03102f59-3d83-473c-a1e0-1983a8bb1659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70848\n",
            "Validation set size: 7872\n",
            "Test set size: 19681\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = train_test_split(dataset, shuffle=True, test_size=0.2, random_state=42)\n",
        "train_dataset, val_dataset = train_test_split(train_dataset, shuffle=True, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T17:30:22.655420Z",
          "iopub.status.busy": "2024-05-06T17:30:22.654666Z",
          "iopub.status.idle": "2024-05-06T20:19:21.275249Z",
          "shell.execute_reply": "2024-05-06T20:19:21.274369Z",
          "shell.execute_reply.started": "2024-05-06T17:30:22.655385Z"
        },
        "id": "UjJ2Cs7KGxyW"
      },
      "outputs": [],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 64\n",
        "n_epochs = 5\n",
        "print('Making DataLoaders .... .....  ')\n",
        "train_dataloader = get_dataloader(train_dataset, batch_size)\n",
        "val_dataloader=get_dataloader(val_dataset,batch_size)\n",
        "print('Defining Encoder and Decoder .....')\n",
        "encoder = Encoder(vocab.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, vocab.n_words).to(device)\n",
        "train_loss,val_loss=train_model(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=1, plot_every=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T20:19:21.277662Z",
          "iopub.status.busy": "2024-05-06T20:19:21.277362Z",
          "iopub.status.idle": "2024-05-06T20:19:21.284779Z",
          "shell.execute_reply": "2024-05-06T20:19:21.283879Z",
          "shell.execute_reply.started": "2024-05-06T20:19:21.277635Z"
        },
        "id": "Gs2kBilGE0kP"
      },
      "outputs": [],
      "source": [
        "def evaluate_test_samples(encoder, decoder, sentence, vocab):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensor_from_sentence(vocab, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(vocab.index2word[idx.item()])\n",
        "\n",
        "    return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T20:19:21.306555Z",
          "iopub.status.busy": "2024-05-06T20:19:21.306072Z",
          "iopub.status.idle": "2024-05-06T20:19:21.672311Z",
          "shell.execute_reply": "2024-05-06T20:19:21.671346Z",
          "shell.execute_reply.started": "2024-05-06T20:19:21.306527Z"
        },
        "id": "mrDzHYY5GxyX"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly_train(encoder, decoder, vocab, n=10):\n",
        "    for i in range(n):\n",
        "        print(i)\n",
        "        eval_sample = train_dataset.iloc[i:i+1, :]\n",
        "        print('news_article > ', eval_sample['text'].iloc[0])\n",
        "        headline = eval_sample['headlines'].iloc[0]\n",
        "        print('original_headline = ', headline)\n",
        "        output_words = evaluate_test_samples(encoder, decoder, eval_sample.text.iloc[0], vocab)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted_headline < ', output_sentence)\n",
        "        print('')\n",
        "        print(f\"meteor score: {nltk.translate.meteor_score.single_meteor_score(headline.split(), output_sentence.split())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T20:19:21.673973Z",
          "iopub.status.busy": "2024-05-06T20:19:21.673612Z",
          "iopub.status.idle": "2024-05-06T20:19:25.270800Z",
          "shell.execute_reply": "2024-05-06T20:19:25.269820Z",
          "shell.execute_reply.started": "2024-05-06T20:19:21.673937Z"
        },
        "id": "UPZCJgn1NlQ5",
        "outputId": "9990fe04-a46f-4507-90d8-f3f84422d363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'encoder' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1e0cb41e6c9b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluateRandomly_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "evaluateRandomly_train(encoder, decoder, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T20:19:25.272381Z",
          "iopub.status.busy": "2024-05-06T20:19:25.272107Z",
          "iopub.status.idle": "2024-05-06T20:19:25.279290Z",
          "shell.execute_reply": "2024-05-06T20:19:25.278366Z",
          "shell.execute_reply.started": "2024-05-06T20:19:25.272358Z"
        },
        "id": "z95_dzbE9BRj"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly_test(encoder, decoder, vocab, n=10):\n",
        "    for i in range(n):\n",
        "        print(i)\n",
        "        eval_sample = test_dataset.iloc[i:i+1, :]\n",
        "        print('news_article > ', eval_sample['text'].iloc[0])\n",
        "        headline = eval_sample['headlines'].iloc[0]\n",
        "        print('original_headline = ', headline)\n",
        "        output_words = evaluate_test_samples(encoder, decoder, eval_sample.text.iloc[0], vocab)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted_headline < ', output_sentence)\n",
        "        print('')\n",
        "        print(f\"meteor score: {nltk.translate.meteor_score.single_meteor_score(headline.split(), output_sentence.split())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-06T20:19:25.280933Z",
          "iopub.status.busy": "2024-05-06T20:19:25.280592Z",
          "iopub.status.idle": "2024-05-06T20:19:26.692003Z",
          "shell.execute_reply": "2024-05-06T20:19:26.691036Z",
          "shell.execute_reply.started": "2024-05-06T20:19:25.280899Z"
        },
        "id": "JTD-8Nth9BRj",
        "outputId": "dc57f342-e478-4f7a-d475-557dcd7d0fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "news_article >  students in karnataka will get extra marks if their parents cast votes in the upcoming assembly elections the associated management of primary and secondary schools has announced the encouraging marks will be added in the 201819 academic year the association said after casting their votes parents can visit member schoolsand confirm that they voted by showing the indelible ink mark\n",
            "original_headline =  ktaka students to get extra marks if parents vote in polls\n",
            "predicted_headline <  sc to kerala <EOS>\n",
            "\n",
            "meteor score: 0.04854368932038835\n",
            "1\n",
            "news_article >  syrian antiaircraft defences on monday shot down missiles over two air bases syrias state media said the missiles targeted shayrat air base in the homs province and another base northeast of the capital damascus this comes days after the us uk and france launched air strikes on syrian chemical weapons facilities in retaliation for the alleged chemical attack in douma\n",
            "original_headline =  syria shoots down missiles fired at two air bases\n",
            "predicted_headline <  drone down <EOS>\n",
            "\n",
            "meteor score: 0.05952380952380952\n",
            "2\n",
            "news_article >  a dinosaurlike creatures fossil was found during an excavation on sunday in uttarakhands jaspur a small city 110 km from nainital the fossils hind legs measure around 29 cm while the tail is around 5 cm long found at an abandoned electricity department land the authorities would be sending the remains to dehradunbased wildlife institute of india for further investigation\n",
            "original_headline =  dinosaurlike animals fossil found in uttarakhand\n",
            "predicted_headline <  study <EOS>\n",
            "\n",
            "meteor score: 0.0\n",
            "3\n",
            "news_article >  the uttar pradesh government is planning to form a up muslim waqf board by merging the separate shia and sunni waqf boards to prevent wastage of funds minister of state for waqf mohsin raza said the merged waqf board will have members from both the communities and its chairman will be selected from among them he added \n",
            "original_headline =  up may merge shia sunni waqf boards to prevent fund wastage\n",
            "predicted_headline <  up govt to up govt <EOS>\n",
            "\n",
            "meteor score: 0.09523809523809525\n",
            "4\n",
            "news_article >  egyptian activistactress amal fathy has been given a sentence of two years on charges of spreading false news for uploading a video on facebook wherein she alleged that she faced sexual harassment at a bank fathy was charged with disseminating a video on social media to publicly incite overthrowing the government she has already spent over 140 days in prison\n",
            "original_headline =  egypt actress gets 2 yrs jail for fake news on sexual harassment\n",
            "predicted_headline <  police <EOS>\n",
            "\n",
            "meteor score: 0.0\n",
            "5\n",
            "news_article >  worlds richest person and amazon ceo jeff bezos added 326 billion to his wealth in 2017 which is higher than the gdp of 93 countries according to figures from imf it is also more than the combined gdp for one year of 28 countries bezos net worth is currently 106 billion after amazon shares surged by over 6 this year\n",
            "original_headline =  jeff bezos added more wealth in 2017 than gdp of 93 nations\n",
            "predicted_headline <  jeff bezos <EOS>\n",
            "\n",
            "meteor score: 0.16891891891891891\n",
            "6\n",
            "news_article >  bangladesh cricket teams limited overs captain mashrafe mortaza on tuesday announced that he will retire from t20 international cricket after the end of the series against sri lanka the 33yearold pace bowler has featured in 52 t20i matches for his nation so far picking up 39 wickets and registering 368 runs at an average of 1362\n",
            "original_headline =  bangladeshi captain mortaza announces retirement from t20is\n",
            "predicted_headline <  cricket team <EOS>\n",
            "\n",
            "meteor score: 0.0\n",
            "7\n",
            "news_article >  mexican drug lord joaquin el chapo guzman has claimed that his extradition to us from mexico violated the terms of a usmexico treaty according to the terms guzman had to be transferred to either california or texas however on the day of his extradition mexico waived the terms and consented instead to send him to new york guzmans lawyers said\n",
            "original_headline =  mexican drug lord el chapo questions us extradition legality\n",
            "predicted_headline <  us senator <EOS>\n",
            "\n",
            "meteor score: 0.05952380952380952\n",
            "8\n",
            "news_article >  independent united nations un monitors have accused north korea of supplying ballistic missile systems along with conventional weapons including rocket launchers and surfacetoair missiles to myanmar in a report to the un security councils sanctions committee the monitors also accused north korea of supplying weapons to syria and violating un sanctions by exporting banned commodities \n",
            "original_headline =  n korea supplies ballistic missiles to myanmar un monitors \n",
            "predicted_headline <  n korea <EOS>\n",
            "\n",
            "meteor score: 0.2232142857142857\n",
            "9\n",
            "news_article >  after reports of three amrapali group companies going into insolvency surfaced several home buyers slammed cricketer harbhajan singh who was once the brand ambassador of the company a user claimed that harbhajan and ms dhoni had received free flats from the company while he lost his money harbhajan responded saying even he was made a fool by the company\n",
            "original_headline =  thenga mila hamme harbhajan responds to home buyers\n",
            "predicted_headline <  bigg boss who lost him <EOS>\n",
            "\n",
            "meteor score: 0.0\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "evaluateRandomly_test(encoder, decoder, vocab)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4903724,
          "sourceId": 8261712,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4910375,
          "sourceId": 8270593,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4951191,
          "sourceId": 8336798,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4952181,
          "sourceId": 8338392,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}