{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoUrJN282ls6"
      },
      "source": [
        "# Building a Seq2Seq Model for Headline Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k83EsbR2ls-",
        "outputId": "666fd56f-b89c-4dc3-f289-33d17a565321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pDyIjkcbUe-",
        "outputId": "33c726e4-bc14-483d-973f-631aff2f1bc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TDu_Qcf22ltA"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Dataset/news_summary.csv\", encoding='latin1')  # Replace with the path to your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IA2Yex2T_6hF",
        "outputId": "d4fd993e-04c5-449f-dc9f-da9993ba757f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               headlines  \\\n",
              "98396  CRPF jawan axed to death by Maoists in Chhatti...   \n",
              "98397  First song from Sonakshi Sinha's 'Noor' titled...   \n",
              "98398         'The Matrix' film to get a reboot: Reports   \n",
              "98399  Snoop Dogg aims gun at clown dressed as Trump ...   \n",
              "98400  Madhesi Morcha withdraws support to Nepalese g...   \n",
              "\n",
              "                                                    text  \n",
              "98396  A CRPF jawan was on Tuesday axed to death with...  \n",
              "98397  'Uff Yeh', the first song from the Sonakshi Si...  \n",
              "98398  According to reports, a new version of the 199...  \n",
              "98399  A new music video shows rapper Snoop Dogg aimi...  \n",
              "98400  Madhesi Morcha, an alliance of seven political...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd3ff697-152d-4a1d-82ed-5182d27a15be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>98396</th>\n",
              "      <td>CRPF jawan axed to death by Maoists in Chhatti...</td>\n",
              "      <td>A CRPF jawan was on Tuesday axed to death with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98397</th>\n",
              "      <td>First song from Sonakshi Sinha's 'Noor' titled...</td>\n",
              "      <td>'Uff Yeh', the first song from the Sonakshi Si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98398</th>\n",
              "      <td>'The Matrix' film to get a reboot: Reports</td>\n",
              "      <td>According to reports, a new version of the 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98399</th>\n",
              "      <td>Snoop Dogg aims gun at clown dressed as Trump ...</td>\n",
              "      <td>A new music video shows rapper Snoop Dogg aimi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98400</th>\n",
              "      <td>Madhesi Morcha withdraws support to Nepalese g...</td>\n",
              "      <td>Madhesi Morcha, an alliance of seven political...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd3ff697-152d-4a1d-82ed-5182d27a15be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd3ff697-152d-4a1d-82ed-5182d27a15be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd3ff697-152d-4a1d-82ed-5182d27a15be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-09b9ba64-d28c-4a48-9d99-b0b23acced9d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09b9ba64-d28c-4a48-9d99-b0b23acced9d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-09b9ba64-d28c-4a48-9d99-b0b23acced9d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"headlines\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"First song from Sonakshi Sinha's 'Noor' titled 'Uff Yeh' out\",\n          \"Madhesi Morcha withdraws support to Nepalese government\",\n          \"'The Matrix' film to get a reboot: Reports\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'Uff Yeh', the first song from the Sonakshi Sinha starrer upcoming drama film 'Noor' has been released. The song has been composed by Amaal Mallik with vocals by Armaan Malik and lyrics by Manoj Muntashir. Sonakshi will be seen portraying a Pakistani journalist-writer in the film. Directed by Sunhil Sippy, the film is scheduled to release on April 21.\",\n          \"Madhesi Morcha, an alliance of seven political parties, has withdrawn support to PM Pushpa Kamal Dahal-led Nepal government after it failed to meet a seven-day ultimatum to fulfil their demands including endorsement for the revised Constitution amendment bill. The Morcha has 36 seats in the Parliament, but despite the withdrawal of support, there is no immediate threat to the government.\",\n          \"According to reports, a new version of the 1999 science fiction film 'The Matrix' is in development. Michael B Jordan will reportedly play the lead role in the film. Screenwriter Zak Penn is in talks to write the script of the film, reports added. Actor Keanu Reeves starred in the original film, which was followed by two sequels. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odrZlFGS2ltE"
      },
      "source": [
        "### Why ASCII format is important?\n",
        "- **Standardization**: ASCII format standardizes text data to a set of 128 characters, including commonly used letters, digits, and symbols in English.\n",
        "- **Simplified Encoding/Decoding**: Ensures ease of encoding and decoding processes by utilizing a uniform character set.\n",
        "- **Compatibility**: Helps avoid complications with non-English and special characters found in other encodings like UTF-8.\n",
        "- **Error Reduction**: Using ASCII can reduce errors in text processing tasks, particularly when dealing with large datasets or systems with limited character support.\n",
        "- **Integration Simplicity**: Facilitates easier integration between systems that may not support broader character sets, minimizing complexities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yx9mLRjH2ltC"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(df, col):\n",
        "    # converting language data in data frame to lower case and then storing in sentence variable\n",
        "    sentence = df[col].str.lower()\n",
        "    sentence = sentence.str.replace('[^0-9A-Za-z\\s]+', '', regex=True)\n",
        "    sentence = sentence.str.normalize('NFD')\n",
        "    #encoding the string in sentence in UTF-8 format and ignoring errors if any\n",
        "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8nND_8pH2ltF"
      },
      "outputs": [],
      "source": [
        "dataset['headlines'] = preprocess_text(dataset, 'headlines')\n",
        "dataset['text'] = preprocess_text(dataset, 'text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aI_sbTmh2ltG",
        "outputId": "9e9e1dae-c639-4c7c-83e3-7a1d2e3cd456"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               headlines  \\\n",
              "98396  crpf jawan axed to death by maoists in chhatti...   \n",
              "98397  first song from sonakshi sinhas noor titled uf...   \n",
              "98398            the matrix film to get a reboot reports   \n",
              "98399  snoop dogg aims gun at clown dressed as trump ...   \n",
              "98400  madhesi morcha withdraws support to nepalese g...   \n",
              "\n",
              "                                                    text  \n",
              "98396  a crpf jawan was on tuesday axed to death with...  \n",
              "98397  uff yeh the first song from the sonakshi sinha...  \n",
              "98398  according to reports a new version of the 1999...  \n",
              "98399  a new music video shows rapper snoop dogg aimi...  \n",
              "98400  madhesi morcha an alliance of seven political ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05540264-3d25-4de3-abe7-4179a935be1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>98396</th>\n",
              "      <td>crpf jawan axed to death by maoists in chhatti...</td>\n",
              "      <td>a crpf jawan was on tuesday axed to death with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98397</th>\n",
              "      <td>first song from sonakshi sinhas noor titled uf...</td>\n",
              "      <td>uff yeh the first song from the sonakshi sinha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98398</th>\n",
              "      <td>the matrix film to get a reboot reports</td>\n",
              "      <td>according to reports a new version of the 1999...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98399</th>\n",
              "      <td>snoop dogg aims gun at clown dressed as trump ...</td>\n",
              "      <td>a new music video shows rapper snoop dogg aimi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98400</th>\n",
              "      <td>madhesi morcha withdraws support to nepalese g...</td>\n",
              "      <td>madhesi morcha an alliance of seven political ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05540264-3d25-4de3-abe7-4179a935be1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05540264-3d25-4de3-abe7-4179a935be1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05540264-3d25-4de3-abe7-4179a935be1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ba057b87-bd44-4789-8c8e-06143e4feb8a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba057b87-bd44-4789-8c8e-06143e4feb8a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ba057b87-bd44-4789-8c8e-06143e4feb8a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"headlines\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"first song from sonakshi sinhas noor titled uff yeh out\",\n          \"madhesi morcha withdraws support to nepalese government\",\n          \"the matrix film to get a reboot reports\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"uff yeh the first song from the sonakshi sinha starrer upcoming drama film noor has been released the song has been composed by amaal mallik with vocals by armaan malik and lyrics by manoj muntashir sonakshi will be seen portraying a pakistani journalistwriter in the film directed by sunhil sippy the film is scheduled to release on april 21\",\n          \"madhesi morcha an alliance of seven political parties has withdrawn support to pm pushpa kamal dahalled nepal government after it failed to meet a sevenday ultimatum to fulfil their demands including endorsement for the revised constitution amendment bill the morcha has 36 seats in the parliament but despite the withdrawal of support there is no immediate threat to the government\",\n          \"according to reports a new version of the 1999 science fiction film the matrix is in development michael b jordan will reportedly play the lead role in the film screenwriter zak penn is in talks to write the script of the film reports added actor keanu reeves starred in the original film which was followed by two sequels \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rR1Nw0Tg2ltH"
      },
      "outputs": [],
      "source": [
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "# make the token 1 and 2 ,0 is already reserved for the [pad]\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0:'PAD',1: \"SOS\", 2: \"EOS\"}\n",
        "        self.n_words = 3  # Count SOS and EOS\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcOoV5oIPc24"
      },
      "source": [
        "\n",
        "### **Explanation-**\n",
        "The provided Python script introduces a `Vocab` class specifically tailored for language processing tasks that involve handling vocabulary in various natural language processing (NLP) applications. The class is structured to maintain a mapping of words to their respective indices and to keep a count of the frequency of each word's occurrence.\n",
        "\n",
        "Key elements of the `Vocab` class include:\n",
        "1. **Initialization**: The constructor (`__init__`) sets up three dictionaries:\n",
        "   - `word2index`: Maps words to their unique integer indices.\n",
        "   - `word2count`: Stores the frequency count of each word.\n",
        "   - `index2word`: Maps indices back to their corresponding words.\n",
        "   Additionally, it initializes three special tokens:\n",
        "   - `PAD` (index 0): Used for padding shorter sentences to a common length.\n",
        "   - `SOS` (index 1): \"Start of Sentence\" token, often used in models to signal the beginning of a new sentence.\n",
        "   - `EOS` (index 2): \"End of Sentence\" token, used to indicate the termination of a sentence.\n",
        "\n",
        "2. **Adding Words and Sentences**:\n",
        "   - `add_sentence(sentence)`: This method takes a string input, splits it into individual words, and processes each word through the `add_word` method.\n",
        "   - `add_word(word)`: This method checks if a word is already in the `word2index` dictionary. If it is not, the word is added to this dictionary with an incrementing index, added to the `index2word` dictionary with the corresponding index, and initialized in the `word2count` dictionary with a count of one. If the word is already known, only its count in `word2count` is incremented.\n",
        "\n",
        "3. **Utility and Tracking**:\n",
        "   - The `n_words` attribute keeps track of the total number of unique words, starting from 3 to account for the three special tokens.\n",
        "\n",
        "This class facilitates the construction of a vocabulary from scratch, allowing for dynamic updates as new words are encountered. It is particularly useful in settings where the vocabulary needs to be expanded based on the input data, such as in machine learning models for language translation, text summarization, or other NLP tasks that require tokenization of text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GcOMDzfc2ltI"
      },
      "outputs": [],
      "source": [
        "#create vocab instance\n",
        "vocab = Vocab()\n",
        "\n",
        "_ = dataset.text.apply(lambda x: vocab.add_sentence(x))\n",
        "_ = dataset.headlines.apply(lambda x: vocab.add_sentence(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a0k6r8i2ltI",
        "outputId": "86b4644b-3583-432f-a2fd-abc3a964f6c7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120908"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "vocab.n_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gB87pFBl2ltJ"
      },
      "outputs": [],
      "source": [
        "#calculate and store the length of each text and headline\n",
        "dataset['text_length'] = dataset.text.str.split(' ').apply(lambda x: len(x))\n",
        "dataset['headlines_length'] = dataset.headlines.str.split(' ').apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y-bY02O2ltJ",
        "outputId": "223bf177-84cd-4115-960e-8fc219ab3f73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset.headlines_length.max(), dataset.text_length.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kU3mlDb72ltJ"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH_INPUT = 100\n",
        "MAX_LENGTH_TARGET = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lq_w-HZQ2ltK"
      },
      "outputs": [],
      "source": [
        "# function to convert a sentence into a list of indices based on the vocabulary\n",
        "def indexes_from_sentence(vocab, sentence):\n",
        "    return [vocab.word2index[word] for word in sentence.split(' ')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xByFRT1v2ltK"
      },
      "outputs": [],
      "source": [
        "# convert a sentence into a list of indices, and then appends the EOS_token\n",
        "def tensor_from_sentence(vocab, sentence):\n",
        "    indexes = indexes_from_sentence(vocab, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cYjnq3hN2ltK"
      },
      "outputs": [],
      "source": [
        "# prepare dataloader\n",
        "def get_dataloader(dataset, batch_size):\n",
        "    n = dataset.shape[0]\n",
        "    input_ids = np.zeros((n, MAX_LENGTH_INPUT), dtype=np.int64)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH_TARGET), dtype=np.int64)\n",
        "\n",
        "    for idx in range(n):\n",
        "        inp_ids = indexes_from_sentence(vocab, dataset.text.iloc[idx])\n",
        "        tgt_ids = indexes_from_sentence(vocab, dataset.headlines.iloc[idx])\n",
        "\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a01VvRb2ltK"
      },
      "source": [
        "### Explanation-\n",
        "\n",
        "1. Function Definition and Initial Setup\n",
        "- **Function Initialization**: `get_dataloader(dataset, batch_size)` is designed to accept a dataset containing textual data and headlines, along with a batch size that dictates how many sequences each batch will contain.\n",
        "- **Storage Arrays Creation**: Initializes two numpy arrays, `input_ids` and `target_ids`, with zeros. The arrays are sized based on the total number of entries (`n`) in the dataset and the predefined maximum lengths (`MAX_LENGTH_INPUT` for input texts and `MAX_LENGTH_TARGET` for target headlines). These arrays will hold the indexed representations of each sentence.\n",
        "\n",
        "2. Converting Sentences to Indexed Sequences\n",
        "- **Processing Each Dataset Entry**: Iterates over each entry in the dataset. For each text and headline:\n",
        "  - **Indexing**: Converts the text to a list of indices using `indexes_from_sentence(vocab, dataset.text.iloc[idx])` and does the same for the headline.\n",
        "  - **Appending EOS Tokens**: Adds an EOS token to the end of each indexed list, indicating the end of the sequences. This is critical for models to understand where sequences end during prediction.\n",
        "\n",
        "3. Populating the Storage Arrays\n",
        "- **Filling Arrays**: Each list of indexed words (including the EOS token) for the input texts and target headlines is used to populate corresponding rows in the `input_ids` and `target_ids` arrays. The sequences are left-padded with zeros to ensure that all sequences within a batch have the same length, which is necessary for processing in neural networks.\n",
        "\n",
        "4. Setting Up TensorDataset and DataLoader\n",
        "- **TensorDataset Creation**: Transforms the populated `input_ids` and `target_ids` into PyTorch tensors and combines them into a `TensorDataset`. This dataset facilitates the pairing of each input sequence with its corresponding target sequence, crucial for supervised learning.\n",
        "- **RandomSampler and DataLoader**: Incorporates a `RandomSampler` to shuffle the dataset entries thoroughly. This shuffling prevents the model from learning any biases or patterns from the sequence order in the dataset. The `DataLoader` is then set up with this `TensorDataset` and `RandomSampler`, and configured to yield data in batches of the specified `batch_size`.\n",
        "\n",
        "5. Return of DataLoader\n",
        "- **Output**: Returns the fully configured `train_dataloader`, which is now ready to be used in the training loop of a sequence-to-sequence model. This DataLoader provides batches of indexed, padded, and shuffled sequences, ensuring efficient data handling and contributing to effective model training through improved data variability and computational optimization.\n",
        "\n",
        "This chronologically ordered description delineates each step involved in the data preparation process facilitated by the `get_dataloader` function, making it clear how it contributes to setting up data for efficient training in NLP models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RUNYuG52ltL"
      },
      "source": [
        "\n",
        "\n",
        "One important aspect to note is that in this implementation, we are not utilizing pre-trained embeddings such as Word2Vec. Instead, we are training the embeddings from scratch. This approach is particularly beneficial for large datasets where sufficient data is available to develop robust, domain-specific embeddings without the need for pre-trained models. Even though we do not have a very large dataset in this problem, we are using this strategy for experimentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "p3XewSoU8n8D"
      },
      "outputs": [],
      "source": [
        "#define encoder class\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        # Make LSTM bidirectional\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # When LSTM is bidirectional, the output, hidden and cell state will be for both directions\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        return output, (hidden, cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVDgIYG72ltQ",
        "outputId": "4336b9b6-9f06-49df-e3e4-cde8c9ab8e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(100, 64)\n",
            "  (lstm): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#initialize encoder\n",
        "enc = Encoder(100, 64)\n",
        "print(enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ru12Nnvi2ltQ"
      },
      "outputs": [],
      "source": [
        "#creating simulated input\n",
        "x = torch.randint(1, 100, (1, 61))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6johgvt62ltR"
      },
      "outputs": [],
      "source": [
        "#pass tensor x through encoder model\n",
        "enc_outputs, enc_hidden = enc.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNzft1KY2ltR",
        "outputId": "d8adfcda-cb02-426c-dc08-3e48927462ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_outputs_shape: torch.Size([1, 61, 128])\n",
            "enc_hidden_h_shape: torch.Size([2, 1, 64])\n",
            "enc_hidden_c_shape: torch.Size([2, 1, 64])\n"
          ]
        }
      ],
      "source": [
        "enc_hidden_h_shape = enc_hidden[0].shape\n",
        "enc_hidden_c_shape = enc_hidden[1].shape\n",
        "enc_outputs_shape = enc_outputs.shape\n",
        "\n",
        "print(\"enc_outputs_shape:\", enc_outputs_shape)\n",
        "print(\"enc_hidden_h_shape:\", enc_hidden_h_shape)\n",
        "print(\"enc_hidden_c_shape:\", enc_hidden_c_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qJxtTcD2ltR"
      },
      "source": [
        "\n",
        "The shapes of the outputs from the encoder indicate the following:\n",
        "\n",
        "- enc_outputs_shape: torch.Size([1, 61, 128]) tells us that the encoder output a sequence of 61 time steps for a single batch, and each time step's output is a 128-dimensional vector. This output represents the LSTM's output at each step.\n",
        "- enc_hidden_h_shape: torch.Size([1, 1, 64]) shows that the hidden state is a 64-dimensional vector for a single layer of the LSTM, applicable to one batch. This state captures the learned features from the input sequence up to the last time step.\n",
        "- enc_hidden_c_shape: torch.Size([1, 1, 64]) similarly reveals that the cell state is also a 64-dimensional vector for one layer and one batch, indicating the LSTM's internal state that helps control the flow of information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yq0jALo2ltR"
      },
      "source": [
        "And next, we define the Decoder class. This class generates sequential outputs based on the context from an encoder. It starts with an embedding layer converting input indices into dense vectors. A unidirectional LSTM processes these vectors, using states adapted from the encoder's bidirectional output. The model employs teacher forcing during training, where actual previous outputs are fed as inputs, enhancing learning stability. Outputs are passed through a linear layer, and the sequence of predictions is formed by applying a softmax function, facilitating effective word prediction in generated sequences. This architecture is essential for tasks like machine translation, where accurate sequential generation based on context is crucial. We have given a detailed explanation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vv2w5VTJ2ltR"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size * 2  # Adjust hidden size if states are concatenated\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        # Assuming concatenation of hidden states, adjust LSTM input size\n",
        "        self.lstm = nn.LSTM(hidden_size, self.hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "\n",
        "        # Combine or adapt encoder_hidden to suit unidirectional decoder\n",
        "        encoder_hidden = self.adapt_hidden(encoder_hidden)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH_TARGET):\n",
        "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def adapt_hidden(self, hidden):\n",
        "        # Assuming hidden is a tuple (hidden_state, cell_state) each with dimensions [2, batch_size, hidden_size]\n",
        "        hidden_state, cell_state = hidden\n",
        "        # Concatenate the forward and backward states\n",
        "        hidden_state = torch.cat((hidden_state[0:hidden_state.size(0):2], hidden_state[1:hidden_state.size(0):2]), dim=2)\n",
        "        cell_state = torch.cat((cell_state[0:cell_state.size(0):2], cell_state[1:cell_state.size(0):2]), dim=2)\n",
        "        return (hidden_state, cell_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ9e5KxBEskd"
      },
      "source": [
        "**Explanation-**\n",
        "\n",
        "1. **Initialization (`__init__` method)**:\n",
        "   - **Hidden Size Adjustment**: The decoder initializes with an adjusted `hidden_size`, doubling it to accommodate the concatenated forward and backward states from a bidirectional LSTM encoder.\n",
        "   - **Embedding Layer**: An embedding layer is created to transform input indices into dense vector representations, with the embedding dimension set to `hidden_size`.\n",
        "   - **LSTM Layer**: A unidirectional LSTM is used for decoding. The input size is `hidden_size`, and the output size is the adjusted `hidden_size`.\n",
        "   - **Output Layer**: A linear layer that maps from the LSTM output size to the `output_size`, which typically corresponds to the vocabulary size of the output language or target.\n",
        "\n",
        "2. **Forward Pass (`forward` method)**:\n",
        "   - **Initial Setup**: Starts by preparing a `decoder_input` initialized with the start-of-sequence (SOS) token, ensuring the decoder knows where to begin sequence generation.\n",
        "   - **Adapt Hidden States**: The hidden states from the encoder (which may be bidirectional) are adapted for use in the unidirectional LSTM of the decoder through the `adapt_hidden` method.\n",
        "   - **Sequence Generation Loop**:\n",
        "     - The loop runs for each position up to `MAX_LENGTH_TARGET` to generate the required sequence length.\n",
        "     - **Embedding and Activation**: At each step, the current input token is embedded and passed through a ReLU activation function.\n",
        "     - **LSTM Computation**: The LSTM processes the activated embedding along with the current hidden state.\n",
        "     - **Output Generation**: The LSTM's output is then passed to the linear layer to produce a vector of scores corresponding to the likelihood of each token in the vocabulary.\n",
        "     - **Teacher Forcing Option**: If a `target_tensor` is provided (during training), it uses this tensor's next token as the input for the next step (teacher forcing). Otherwise, it uses the most likely token from the current output.\n",
        "   - **Sequence Concatenation**: The outputs across all time steps are concatenated to form the final sequence.\n",
        "\n",
        "3. **Forward Step (`forward_step` method)**:\n",
        "   - This method is called by the main forward loop of the decoder and handles the processing of input tokens into output tokens for each timestep.\n",
        "\n",
        "4. **Adapt Hidden States (`adapt_hidden` method)**:\n",
        "   - **State Concatenation**: Assuming the encoder's hidden states are from a bidirectional LSTM, this method concatenates the forward and backward components of the hidden and cell states to create a new state suitable for the unidirectional LSTM in the decoder.\n",
        "\n",
        "This structured approach enables the decoder to effectively generate sequences by capturing the dependencies of the input sequence, provided by the encoder's output and adapted states, and transforming them into a coherent output sequence step-by-step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8OM73a_2ltR",
        "outputId": "64530548-e61d-4a99-b020-80e508925554"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#generate random target tensors\n",
        "tgt_tensor = torch.randint(1, 100, (1, 20))\n",
        "tgt_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FtqBDNEY2ltS"
      },
      "outputs": [],
      "source": [
        "#initialise the decoder class\n",
        "dec = Decoder(64, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Y72M2w52Dq5X"
      },
      "outputs": [],
      "source": [
        "# Move your models to the designated device\n",
        "encoder = enc.to(device)\n",
        "decoder = dec.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FXPY9hIDDtFj"
      },
      "outputs": [],
      "source": [
        "# When you load or create tensors, send them to the same device\n",
        "enc_outputs = enc_outputs.to(device)\n",
        "(h,c) = enc_hidden\n",
        "enc_hidden_gpu=h.to(device),c.to(device)\n",
        "tgt_tensor = tgt_tensor.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "y5pBZ4Q02ltS"
      },
      "outputs": [],
      "source": [
        "#execute forward pass of decoder instance\n",
        "decoder_outputs, decoder_hidden= dec.forward(enc_outputs, enc_hidden_gpu, tgt_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRQuUr892ltS",
        "outputId": "1c27f321-b806-447f-9bda-6b0e2789ccf2",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_outputs_shape: torch.Size([1, 20, 100])\n",
            "decoder_hidden_h_shape: torch.Size([1, 1, 128])\n",
            "decoder_hidden_c_shape: torch.Size([1, 1, 128])\n"
          ]
        }
      ],
      "source": [
        "decoder_hidden_h_shape = decoder_hidden[0].shape\n",
        "decoder_hidden_c_shape = decoder_hidden[1].shape\n",
        "decoder_outputs_shape = decoder_outputs.shape\n",
        "\n",
        "print(\"decoder_outputs_shape:\", decoder_outputs_shape)\n",
        "print(\"decoder_hidden_h_shape:\", decoder_hidden_h_shape)\n",
        "print(\"decoder_hidden_c_shape:\", decoder_hidden_c_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krsamkHi2ltT",
        "outputId": "1b827f65-e125-4699-ee5d-8f21139cc3cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70848\n",
            "Validation set size: 7872\n",
            "Test set size: 19681\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = train_test_split(dataset, shuffle=True, test_size=0.2, random_state=42)\n",
        "train_dataset, val_dataset = train_test_split(train_dataset, shuffle=True, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4QbjUgmB8n8L"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    total_loss = 0\n",
        "    for input_tensor, target_tensor in tqdm(dataloader):\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate_model(dataloader, encoder, decoder, criterion):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for input_tensor, target_tensor in tqdm(dataloader):\n",
        "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "            decoder_outputs, decoder_hidden = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "            loss = criterion(\n",
        "                decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "                target_tensor.view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def train_model(train_dataloader, valid_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "                print_every=100, plot_every=100):\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        print(f\"Epoch: {epoch}/{n_epochs}\")\n",
        "        # Training\n",
        "        train_loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer,\n",
        "                                 decoder_optimizer, criterion)\n",
        "        print_loss_total += train_loss\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(f\"Train Loss: {round(print_loss_avg, 3)}\")\n",
        "\n",
        "        # Validation\n",
        "        print('Validation....')\n",
        "        valid_loss = evaluate_model(valid_dataloader, encoder, decoder, criterion)\n",
        "        valid_losses.append(valid_loss)\n",
        "        print(f\"Validation Loss: {round(valid_loss, 3)}\")\n",
        "\n",
        "        # Save the model if it has the best validation loss so far\n",
        "        if valid_loss < best_val_loss:\n",
        "            best_val_loss = valid_loss\n",
        "            torch.save(encoder.state_dict(), 'best_encoder.pth')\n",
        "            torch.save(decoder.state_dict(), 'best_decoder.pth')\n",
        "            print(f\"Saved Best Model at Epoch: {epoch}\")\n",
        "\n",
        "    return train_losses, valid_losses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sdCMjtif5dC"
      },
      "source": [
        "**Explanation:**\n",
        "\n",
        "#### Training Epoch (`train_epoch` function):\n",
        "- **Initialization**: Sets the total loss for the epoch to zero.\n",
        "- **Batch Processing**:\n",
        "  - Zeroes out gradients for both encoder and decoder optimizers to prevent accumulation from previous iterations.\n",
        "  - Computes encoder and decoder outputs by passing the input tensors through the models.\n",
        "  - Calculates the loss using a criterion that compares the decoder's output to the target tensor.\n",
        "  - Performs backpropagation by calling `loss.backward()`.\n",
        "  - Updates the encoder and decoder weights using their respective optimizers.\n",
        "  - Accumulates the loss over all batches.\n",
        "- **Epoch Conclusion**: Returns the average loss for the epoch.\n",
        "\n",
        "#### Evaluation (`evaluate_model` function):\n",
        "- **Initialization**: Prepares for evaluation by setting the total loss to zero.\n",
        "- **Batch Evaluation**:\n",
        "  - With gradient calculations disabled (`torch.no_grad()`), processes each batch by computing encoder and decoder outputs, and calculates loss similarly to the training phase but without updating weights.\n",
        "  - Aggregates total loss across all batches.\n",
        "- **Evaluation Conclusion**: Returns the average loss for the validation dataset.\n",
        "\n",
        "#### Model Training (`train_model` function):\n",
        "- **Setup**: Initializes optimizers for the encoder and decoder and sets the loss criterion.\n",
        "- **Epoch Loop**:\n",
        "  - For each epoch, calls `train_epoch` to train the model and `evaluate_model` to assess its performance on the validation set.\n",
        "  - Logs and prints training loss periodically and updates the running total of the training loss.\n",
        "  - After each epoch, evaluates the model, logs the validation loss, and saves the model state if it has the best validation loss observed so far.\n",
        "- **Training Conclusion**: Completes the training after the specified number of epochs and returns lists of training and validation losses for further analysis.\n",
        "\n",
        "This workflow provides a comprehensive mechanism for training and evaluating a seq2seq model, crucial for tasks like machine translation or time series prediction, where learning sequential dependencies is key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwaQaqiPhNIZ"
      },
      "source": [
        "Now let us create a workflow to for our sequence-to-sequence model.\n",
        "It begins by setting key parameters: hidden_size at 256, batch_size at 64, and n_epochs equaling 10. The code then initializes data loaders for both training and validation datasets, ensuring that data is batched and ready for processing. Subsequently, the Encoder and Decoder are defined with specified sizes and moved to the appropriate computing device (GPU or CPU). The encoder and decoder are integral to the seq2seq model, handling input sequence processing and generating output sequences. The train_model function is called to train these models over the defined number of epochs, with specific intervals for printing the training loss and validating the model's performance on unseen data. This training loop is crucial for adjusting the model's weights based on error gradients and improving its prediction accuracy over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugOlZasB2ltU",
        "outputId": "6e237dbd-aef5-49b7-b2d8-d75cefe7bb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making DataLoaders .... .....  \n",
            "Defining Encoder and Decoder .....\n",
            "Epoch: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1107/1107 [05:54<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.715\n",
            "Validation....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [00:10<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.235\n",
            "Saved Best Model at Epoch: 1\n",
            "Epoch: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1107/1107 [05:58<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.855\n",
            "Validation....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [00:10<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.872\n",
            "Saved Best Model at Epoch: 2\n",
            "Epoch: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1107/1107 [05:58<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.327\n",
            "Validation....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [00:10<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.717\n",
            "Saved Best Model at Epoch: 3\n",
            "Epoch: 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1107/1107 [05:58<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.914\n",
            "Validation....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [00:10<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.663\n",
            "Saved Best Model at Epoch: 4\n",
            "Epoch: 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1107/1107 [05:58<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.592\n",
            "Validation....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [00:10<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.659\n",
            "Saved Best Model at Epoch: 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3.7154121689680144,\n",
              "  2.8548559634235384,\n",
              "  2.3265680512977056,\n",
              "  1.9142504540669993,\n",
              "  1.5915162553632163],\n",
              " [3.2353205448243676,\n",
              "  2.871736175645658,\n",
              "  2.717054843902588,\n",
              "  2.6627919383165315,\n",
              "  2.659163539002581])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 64\n",
        "n_epochs = 5\n",
        "print('Making DataLoaders .... .....  ')\n",
        "train_dataloader = get_dataloader(train_dataset, batch_size)\n",
        "val_dataloader=get_dataloader(val_dataset,batch_size)\n",
        "print('Defining Encoder and Decoder .....')\n",
        "encoder = Encoder(vocab.n_words, hidden_size).to(device)\n",
        "decoder = Decoder(hidden_size, vocab.n_words).to(device)\n",
        "\n",
        "train_model(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=1, plot_every=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jJFRT3NF2ltV"
      },
      "outputs": [],
      "source": [
        "def evaluate_test_samples(encoder, decoder, sentence, vocab):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensor_from_sentence(vocab, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(vocab.index2word[idx.item()])\n",
        "\n",
        "    return decoded_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy628b1_Tzs3"
      },
      "source": [
        "\n",
        "The NLTK METEOR score is a metric used to evaluate the quality of machine-generated text against a reference or human-generated text. It calculates a similarity score based on the harmonic mean of unigram precision and recall, with a penalty term for matching chunks. It accounts for variations in word order, synonyms, and paraphrases by aligning words between the generated and reference texts. This alignment is performed using a WordNet-based matching algorithm. The resulting score ranges from 0 to 1, where higher scores indicate better similarity between the generated and reference texts, thus reflecting the quality of the generated text.\n",
        "\n",
        "And then we run this cell. Make sure the NLTK packages are downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3_BjbhX_RCX",
        "outputId": "3e65a1ef-c6eb-4a22-ae97-83e20f0961bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "def evaluateRandomly_train(encoder, decoder, vocab, n=10):\n",
        "    for i in range(n):\n",
        "        print(i)\n",
        "        eval_sample = train_dataset.iloc[i:i+1, :]\n",
        "        print('news_article > ', eval_sample['text'].iloc[0])\n",
        "        headline = eval_sample['headlines'].iloc[0]\n",
        "        print('original_headline = ', headline)\n",
        "        output_words = evaluate_test_samples(encoder, decoder, eval_sample.text.iloc[0], vocab)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted_headline < ', output_sentence)\n",
        "        print(f\"meteor score: {nltk.translate.meteor_score.single_meteor_score(headline.split(), output_sentence.split())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPdp-PQEBiel",
        "outputId": "66bc2b9a-bb1b-4f1a-ff68-2893ac67ec0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "news_article >  a study by financial services company ubs has revealed a person working in mumbai has to work 1147 days to afford the iphone x while a delhi person has to work 1005 days for the same a cairo person has to work the most for 1332 days while a person in zurich can afford iphone x in only 47 days\n",
            "original_headline =  how many days one has to work around the world to buy iphone x\n",
            "predicted_headline <  man in a year elon musk <EOS>\n",
            "meteor score: 0.03759398496240601\n",
            "1\n",
            "news_article >  catalonias independence from spain would not enjoy international recognition france said on monday ahead of catalan regional governments announcement of last weeks independence vote result this crisis needs to be resolved through dialogue at all levels of spanish politics france urged earlier catalonia had claimed that 90 of the participants voted in favour of independence\n",
            "original_headline =  catalan independence would not be recognised france\n",
            "predicted_headline <  catalan independence <EOS>\n",
            "meteor score: 0.2840909090909091\n",
            "2\n",
            "news_article >  an international team of researchers has claimed the ambitious paris climate goal to limit global warming at 15c by 2100 is still possible a researcher associated with the new analysis said in 2015 the carbon cuts needed were incompatible with democracy however with the current dip in prices of renewables a 66 chance of meeting the goal still exists\n",
            "original_headline =  paris deals 15c limit still achievable claims new study\n",
            "predicted_headline <  paris climate pullout <EOS>\n",
            "meteor score: 0.058823529411764705\n",
            "3\n",
            "news_article >  ahead of pm narendra modis visit to dehraduns forest research institute on international yoga day uttarakhands forest department has started a drive to clear the area of snakes and monkeys we dont want any inconvenience for the participants as the campus has a dense forest we have so far caught and released two snakes divisional forest officer rajeev dhiman said\n",
            "original_headline =  yoga day venue to be cleared of snakes ahead of pms visit\n",
            "predicted_headline <  at funeral in odisha <EOS>\n",
            "meteor score: 0.0\n",
            "4\n",
            "news_article >  police on tuesday arrested around 70 gangsters after crashing the birthday party of their kingpin in chennai the police were acting on an intel and intercepted a car that was carrying some of the gangsters to the venue the police reached the venue when the kingpin who managed to escape later was cutting his birthday cake with a machete\n",
            "original_headline =  chennai police crash birthday party arrest 70 gangsters\n",
            "predicted_headline <  police on birthday <EOS>\n",
            "meteor score: 0.13157894736842105\n",
            "5\n",
            "news_article >  france will make school education compulsory from the age of three instead of six president emmanuel macron announced on tuesday the move is a part of the governments reform to make education accessible to everyone irrespective of their financial status as per government records nearly 98 french children are enrolled at school at the age of three\n",
            "original_headline =  france to make school education compulsory from age 3\n",
            "predicted_headline <  france to make free <EOS>\n",
            "meteor score: 0.3423772609819121\n",
            "6\n",
            "news_article >  pope francis was hit by an object resembling a towel thrown at him from the crowds gathered in chiles capital santiago the pontiff who was unharmed ignored the action and smiled notably popes visit was marked by protests over alleged sexual abuse of children within the catholic church\n",
            "original_headline =  video pope francis hit by object during his chile visit\n",
            "predicted_headline <  pope francis <EOS>\n",
            "meteor score: 0.20161290322580647\n",
            "7\n",
            "news_article >  dubai plans to develop a 17 billion over 10000 crore tourist resort on two manmade islands it is building on either side of the burj al arab a luxury sailshaped hotel marsa al arab will comprise two islands one for family tourism and the second featuring luxury villas and a private marina the project will be completed by late 2020 \n",
            "original_headline =  dubai plans 10000 crore project on new artificial islands\n",
            "predicted_headline <  dubai dubai <EOS>\n",
            "meteor score: 0.05952380952380952\n",
            "8\n",
            "news_article >  former world number ones roger federer and novak djokovic have called for an increase in the pay players earn at the grand slam tournaments australian open tournament director craig tiley has reportedly outlined plans to boost prize money at the opening grand slam of the year from 55 million to 100 million over the next five years\n",
            "original_headline =  federer djokovic call for higher prize money at grand slams\n",
            "predicted_headline <  djokovic djokovic <EOS>\n",
            "meteor score: 0.053763440860215055\n",
            "9\n",
            "news_article >  the uttar pradesh police on tuesday denied media reports clarifying that it had nothing to do with the arrest of eight donkeys which were reportedly jailed for four days for eating plants worth 5 lakh reports had quoted jail authorities claiming the donkeys which were let loose by the owner despite a warning were jailed for destroying the expensive plants\n",
            "original_headline =  up police denies report it jailed donkeys for eating plants\n",
            "predicted_headline <  up police to customers <EOS>\n",
            "meteor score: 0.19736842105263158\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "evaluateRandomly_train(encoder, decoder, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TuAc3Xcx_6hR"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly_test(encoder, decoder, vocab, n=10):\n",
        "    for i in range(n):\n",
        "        print(i)\n",
        "        eval_sample = test_dataset.iloc[i:i+1, :]\n",
        "        print('news_article > ', eval_sample['text'].iloc[0])\n",
        "        headline = eval_sample['headlines'].iloc[0]\n",
        "        print('original_headline = ', headline)\n",
        "        output_words = evaluate_test_samples(encoder, decoder, eval_sample.text.iloc[0], vocab)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('predicted_headline < ', output_sentence)\n",
        "        print('')\n",
        "        print(f\"'meteor score:' {nltk.translate.meteor_score.single_meteor_score(headline.split(), output_sentence.split())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jVk0eZQG_6hR",
        "outputId": "b3e7abdc-3b00-44b9-ed14-d9a15a390bcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "news_article >  students in karnataka will get extra marks if their parents cast votes in the upcoming assembly elections the associated management of primary and secondary schools has announced the encouraging marks will be added in the 201819 academic year the association said after casting their votes parents can visit member schoolsand confirm that they voted by showing the indelible ink mark\n",
            "original_headline =  ktaka students to get extra marks if parents vote in polls\n",
            "predicted_headline <  students in ktaka <EOS>\n",
            "\n",
            "'meteor score:' 0.14563106796116504\n",
            "1\n",
            "news_article >  syrian antiaircraft defences on monday shot down missiles over two air bases syrias state media said the missiles targeted shayrat air base in the homs province and another base northeast of the capital damascus this comes days after the us uk and france launched air strikes on syrian chemical weapons facilities in retaliation for the alleged chemical attack in douma\n",
            "original_headline =  syria shoots down missiles fired at two air bases\n",
            "predicted_headline <  air strikes air base <EOS>\n",
            "\n",
            "'meteor score:' 0.2180232558139535\n",
            "2\n",
            "news_article >  a dinosaurlike creatures fossil was found during an excavation on sunday in uttarakhands jaspur a small city 110 km from nainital the fossils hind legs measure around 29 cm while the tail is around 5 cm long found at an abandoned electricity department land the authorities would be sending the remains to dehradunbased wildlife institute of india for further investigation\n",
            "original_headline =  dinosaurlike animals fossil found in uttarakhand\n",
            "predicted_headline <  crocodile found hanging <EOS>\n",
            "\n",
            "'meteor score:' 0.08620689655172413\n",
            "3\n",
            "news_article >  the uttar pradesh government is planning to form a up muslim waqf board by merging the separate shia and sunni waqf boards to prevent wastage of funds minister of state for waqf mohsin raza said the merged waqf board will have members from both the communities and its chairman will be selected from among them he added \n",
            "original_headline =  up may merge shia sunni waqf boards to prevent fund wastage\n",
            "predicted_headline <  up madrasas to up govt <EOS>\n",
            "\n",
            "'meteor score:' 0.09523809523809525\n",
            "4\n",
            "news_article >  egyptian activistactress amal fathy has been given a sentence of two years on charges of spreading false news for uploading a video on facebook wherein she alleged that she faced sexual harassment at a bank fathy was charged with disseminating a video on social media to publicly incite overthrowing the government she has already spent over 140 days in prison\n",
            "original_headline =  egypt actress gets 2 yrs jail for fake news on sexual harassment\n",
            "predicted_headline <  jailed for sexual misconduct <EOS>\n",
            "\n",
            "'meteor score:' 0.2261553588987217\n",
            "5\n",
            "news_article >  worlds richest person and amazon ceo jeff bezos added 326 billion to his wealth in 2017 which is higher than the gdp of 93 countries according to figures from imf it is also more than the combined gdp for one year of 28 countries bezos net worth is currently 106 billion after amazon shares surged by over 6 this year\n",
            "original_headline =  jeff bezos added more wealth in 2017 than gdp of 93 nations\n",
            "predicted_headline <  bezos added richer than hungarys 2017 <EOS>\n",
            "\n",
            "'meteor score:' 0.27445652173913043\n",
            "6\n",
            "news_article >  bangladesh cricket teams limited overs captain mashrafe mortaza on tuesday announced that he will retire from t20 international cricket after the end of the series against sri lanka the 33yearold pace bowler has featured in 52 t20i matches for his nation so far picking up 39 wickets and registering 368 runs at an average of 1362\n",
            "original_headline =  bangladeshi captain mortaza announces retirement from t20is\n",
            "predicted_headline <  bdesh captain <EOS>\n",
            "\n",
            "'meteor score:' 0.07575757575757576\n",
            "7\n",
            "news_article >  mexican drug lord joaquin el chapo guzman has claimed that his extradition to us from mexico violated the terms of a usmexico treaty according to the terms guzman had to be transferred to either california or texas however on the day of his extradition mexico waived the terms and consented instead to send him to new york guzmans lawyers said\n",
            "original_headline =  mexican drug lord el chapo questions us extradition legality\n",
            "predicted_headline <  mexico mexico mexico <EOS>\n",
            "\n",
            "'meteor score:' 0.0\n",
            "8\n",
            "news_article >  independent united nations un monitors have accused north korea of supplying ballistic missile systems along with conventional weapons including rocket launchers and surfacetoair missiles to myanmar in a report to the un security councils sanctions committee the monitors also accused north korea of supplying weapons to syria and violating un sanctions by exporting banned commodities \n",
            "original_headline =  n korea supplies ballistic missiles to myanmar un monitors \n",
            "predicted_headline <  un un un <EOS>\n",
            "\n",
            "'meteor score:' 0.058823529411764705\n",
            "9\n",
            "news_article >  after reports of three amrapali group companies going into insolvency surfaced several home buyers slammed cricketer harbhajan singh who was once the brand ambassador of the company a user claimed that harbhajan and ms dhoni had received free flats from the company while he lost his money harbhajan responded saying even he was made a fool by the company\n",
            "original_headline =  thenga mila hamme harbhajan responds to home buyers\n",
            "predicted_headline <  after he had you sehwag <EOS>\n",
            "\n",
            "'meteor score:' 0.0\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "evaluateRandomly_test(encoder, decoder, vocab)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4903249,
          "sourceId": 8261096,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4903724,
          "sourceId": 8261712,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}