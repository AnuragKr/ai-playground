{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWMVcnnaoSUM",
        "outputId": "e8afae85-4833-4398-d6fb-005925887ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.11\n",
            "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (0.3.60)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (0.3.8)\n",
            "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.11)\n",
            "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1.22.4 (from langchain==0.3.11)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m965.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.11) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11) (1.20.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.11) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.11) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.11) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.11) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.11) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain==0.3.11) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.11) (1.3.1)\n",
            "Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, langsmith, langchain\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.42\n",
            "    Uninstalling langsmith-0.3.42:\n",
            "      Successfully uninstalled langsmith-0.3.42\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.11 langsmith-0.2.11 numpy-1.26.4\n",
            "Collecting langchain-openai==0.2.12\n",
            "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.12) (0.3.60)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.12) (1.81.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.12) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.4.0)\n",
            "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.2.12\n",
            "Collecting langchain-community==0.3.11\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.11)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.11)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.11 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (0.3.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (0.3.60)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (0.2.11)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.11)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.11) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.3.1)\n",
            "Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.11 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.11\n",
        "!pip install langchain-openai==0.2.12\n",
        "!pip install langchain-community==0.3.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5rOqCyianbP"
      },
      "source": [
        "## Setup necessary system environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1PIStD04Zp9p"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDWhgxCy5bA6"
      },
      "source": [
        "## Load Necessary Dependencies and ChatGPT LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9GYhyRFRuJXG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mY2bapqfuWq1"
      },
      "outputs": [],
      "source": [
        "chatgpt = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDkpvGDhMGV"
      },
      "source": [
        "## Project 1: Review Analyst\n",
        "\n",
        "We are building an AI system to be able to look at customer reviews and do some complex analysis. for each review get ChatGPT to do the following:\n",
        "\n",
        "  - Summarize the review. The summary should be at most 3 lines.\n",
        "  - Highlight both the positives and negatives\n",
        "  - Display the overall sentiment of the review (positive, negative, neutral)\n",
        "  - Display a list of 3 - 5 emotions expressed by the customer in the review\n",
        "  - If the sentiment is positive or neutral write an email and thank them for the review\n",
        "  - If the sentiment is negative apologize and write an email with an appropriate response\n",
        "\n",
        "Try to get the response in a nice structured format using an output parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P_TrLpRAIXM"
      },
      "source": [
        "### Access Customer Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hRbBZB57hT0G"
      },
      "outputs": [],
      "source": [
        "reviews = [\n",
        "    f\"\"\"\n",
        "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
        "    The sound quality is impressively clear with just the right amount of bass.\n",
        "    It's also waterproof, which tested true during a recent splashing incident.\n",
        "    Though it's compact, the volume can really fill the space.\n",
        "    The price was a bargain for such high-quality sound.\n",
        "    Shipping was also on point, arriving two days early in secure packaging.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Purchased a new gaming keyboard because of its rave reviews about responsiveness and backlighting.\n",
        "    It hasn't disappointed. The keys have a satisfying click and the LED colors are vibrant,\n",
        "    enhancing my gaming experience significantly. Price-wise, it's quite competitive,\n",
        "    and I feel like I got a good deal. The delivery was swift, and it came well-protected,\n",
        "    ensuring no damage during transport.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Ordered a set of wireless earbuds for running, and they've been a letdown.\n",
        "    The sound constantly cuts out, and the fit is uncomfortable after only a few minutes of use.\n",
        "    They advertised a 12-hour battery life, but I'm barely getting four hours.\n",
        "    Considering the cost, I expected better quality and performance.\n",
        "    They did arrive on time, but the positives end there. I'm already looking into a return.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    The tablet stand I bought was touted as being sturdy and adjustable,\n",
        "    but it's anything but. It wobbles with the slightest touch,\n",
        "    and the angles are not holding up as promised. It feels like a breeze could knock it over.\n",
        "    It was also pricier than others I've seen, which adds to the disappointment.\n",
        "    It did arrive promptly, but what's the use if the product doesn't meet basic expectations?\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Needed a new kitchen blender, but this model has been a nightmare.\n",
        "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
        "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
        "    I thought the brand meant quality, but this product has proven me wrong.\n",
        "    Plus, it arrived three days late. Definitely not worth the expense.\n",
        "    \"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz9SIYmYALOm"
      },
      "source": [
        "### Define Output Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HK0u7biN7uDh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define your desired data structure - like a python data class.\n",
        "class ReviewAnalysisResponse(BaseModel):\n",
        "    summary: str = Field(description=\"A brief summary of the customer review with maximum 3 lines\")\n",
        "    positives: list = Field(description=\"A list showing the positives mentioned by the customer in the review if any - max 3 points\")\n",
        "    negatives: list = Field(description=\"A list showing the negatives mentioned by the customer in the review if any - max 3 points\")\n",
        "    sentiment: str = Field(description=\"One word showing the sentiment of the review - positive, negative or neutral\")\n",
        "    emotions: list = Field(description=\"A list of 3 - 5 emotions expressed by the customer in the review\")\n",
        "    email: str = Field(description=\"Detailed email to the customer based on the sentiment\")\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = PydanticOutputParser(pydantic_object=ReviewAnalysisResponse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8awL6dAONh"
      },
      "source": [
        "### Create the input prompt for the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0TylxOCZ85O1"
      },
      "outputs": [],
      "source": [
        "# create the final prompt with formatting instructions from the parser\n",
        "prompt_txt = \"\"\"\n",
        "             Analyze the given customer review below and generate the response based on the instructions\n",
        "             mentioned below in the format instructions.\n",
        "             Also remember to write a detailed email response for the email field based on these conditions:\n",
        "               - email should be addressed to Dear Customer and signed with Service Agent\n",
        "               - thank them if the review is positive or neutral\n",
        "               - apologize if the review is negative\n",
        "\n",
        "             Format Instructions:\n",
        "             {format_instructions}\n",
        "\n",
        "             Review:\n",
        "             {review}\n",
        "            \"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_txt,\n",
        "    input_variables=[\"review\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE0l_m31AQ5k"
      },
      "source": [
        "### Create a LCEL LLM Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SWfHWjm-9HuD"
      },
      "outputs": [],
      "source": [
        "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
        "chain = (prompt\n",
        "           |\n",
        "         chatgpt\n",
        "           |\n",
        "         parser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ivaPOrATnR"
      },
      "source": [
        "### Format the input reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBPSeLKA9N5M",
        "outputId": "0b12d74a-7b90-44eb-e913-eb22b2d11d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': \"\\n    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\\n    The sound quality is impressively clear with just the right amount of bass.\\n    It's also waterproof, which tested true during a recent splashing incident.\\n    Though it's compact, the volume can really fill the space.\\n    The price was a bargain for such high-quality sound.\\n    Shipping was also on point, arriving two days early in secure packaging.\\n    \"}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "reviews_formatted = [{'review': review} for review in reviews]\n",
        "reviews_formatted[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHbJvZlYAVcH"
      },
      "source": [
        "### Get responses from the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tpH9R-iO9Wbq"
      },
      "outputs": [],
      "source": [
        "responses = chain.map().invoke(reviews_formatted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7wS4_lnAYAL"
      },
      "source": [
        "### View LLM responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHJpeC5f9ZfK",
        "outputId": "09485f53-3315-4cdc-963d-d3b10730559e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary:\n",
            "The customer is highly satisfied with the Bluetooth speaker, praising its sound quality, waterproof feature, and value for money. They also appreciated the prompt shipping.\n",
            "positives:\n",
            "['Impressive sound quality with clear audio and good bass', 'Waterproof feature works effectively', 'Compact size with powerful volume']\n",
            "negatives:\n",
            "[]\n",
            "sentiment:\n",
            "positive\n",
            "emotions:\n",
            "['satisfaction', 'happiness', 'excitement']\n",
            "email:\n",
            "Dear Customer,\n",
            "\n",
            "Thank you for your wonderful review! We're thrilled to hear that you are enjoying your new Bluetooth speaker and that it met your expectations in terms of sound quality, waterproof capability, and value for money. We also appreciate your feedback on the prompt shipping. If you have any further questions or need assistance, feel free to reach out.\n",
            "\n",
            "Best regards,\n",
            "Service Agent\n",
            "-----\n",
            "\n",
            "\n",
            "summary:\n",
            "The customer is highly satisfied with their new gaming keyboard, praising its responsiveness, backlighting, and competitive pricing. They also appreciated the swift delivery and protective packaging.\n",
            "positives:\n",
            "['Responsive keys with a satisfying click', 'Vibrant LED colors enhancing gaming experience', 'Competitive pricing and good deal']\n",
            "negatives:\n",
            "[]\n",
            "sentiment:\n",
            "positive\n",
            "emotions:\n",
            "['satisfaction', 'excitement', 'contentment']\n",
            "email:\n",
            "Dear Customer,\n",
            "\n",
            "Thank you for your wonderful review! We are thrilled to hear that you are enjoying your new gaming keyboard and that it has met your expectations in terms of responsiveness and backlighting. It's great to know that you found the pricing competitive and that the delivery was swift and secure.\n",
            "\n",
            "We appreciate your feedback and hope you continue to have an excellent gaming experience with your new keyboard!\n",
            "\n",
            "Best regards,\n",
            "Service Agent\n",
            "-----\n",
            "\n",
            "\n",
            "summary:\n",
            "The customer is disappointed with the wireless earbuds due to sound issues, uncomfortable fit, and poor battery life. They are considering a return.\n",
            "positives:\n",
            "['Arrived on time']\n",
            "negatives:\n",
            "['Sound cuts out', 'Uncomfortable fit', 'Poor battery life']\n",
            "sentiment:\n",
            "negative\n",
            "emotions:\n",
            "['disappointment', 'frustration', 'dissatisfaction']\n",
            "email:\n",
            "Dear Customer,\n",
            "\n",
            "Thank you for your feedback regarding the wireless earbuds. We sincerely apologize for the issues you've experienced with the sound quality, fit, and battery life. Your satisfaction is important to us, and we understand how disappointing it can be when a product does not meet your expectations. \n",
            "\n",
            "If you would like assistance with the return process or if there is anything else we can do to help, please do not hesitate to reach out. \n",
            "\n",
            "Thank you for bringing this to our attention.\n",
            "\n",
            "Best regards,\n",
            "Service Agent\n",
            "-----\n",
            "\n",
            "\n",
            "summary:\n",
            "The customer is disappointed with the tablet stand's stability and adjustability, feeling it does not meet expectations despite prompt delivery.\n",
            "positives:\n",
            "['Arrived promptly']\n",
            "negatives:\n",
            "['Wobbles with the slightest touch', 'Angles do not hold up as promised', 'Pricier than other options']\n",
            "sentiment:\n",
            "negative\n",
            "emotions:\n",
            "['disappointment', 'frustration', 'dissatisfaction']\n",
            "email:\n",
            "Dear Customer,\n",
            "\n",
            "Thank you for your feedback regarding the tablet stand. We sincerely apologize for the disappointment you've experienced with its stability and adjustability. Your concerns are important to us, and we strive to ensure our products meet the highest standards. If you would like to discuss this further or explore options for a return or exchange, please feel free to reach out.\n",
            "\n",
            "Thank you for bringing this to our attention.\n",
            "\n",
            "Best regards,\n",
            "Service Agent\n",
            "-----\n",
            "\n",
            "\n",
            "summary:\n",
            "The customer is dissatisfied with the kitchen blender, citing performance issues, noise, and delivery delays.\n",
            "positives:\n",
            "[]\n",
            "negatives:\n",
            "['Struggles with tougher foods', 'Incredibly noisy', \"'Easy-clean' feature is ineffective\", 'Arrived three days late']\n",
            "sentiment:\n",
            "negative\n",
            "emotions:\n",
            "['frustration', 'disappointment', 'anger']\n",
            "email:\n",
            "Dear Customer,\n",
            "\n",
            "Thank you for taking the time to share your feedback regarding the kitchen blender. We sincerely apologize for the issues you have experienced with its performance, noise level, and the delivery delay. Your satisfaction is important to us, and we are committed to addressing your concerns. \n",
            "\n",
            "Please feel free to reach out to us for any further assistance or to discuss a possible resolution. \n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Best regards,\n",
            "Service Agent\n",
            "-----\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-1a3230de531d>:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  for k,v in response.dict().items():\n"
          ]
        }
      ],
      "source": [
        "for response in responses:\n",
        "  for k,v in response.dict().items():\n",
        "    print(f'{k}:\\n{v}')\n",
        "  print('-----')\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEtB1IOimA0i"
      },
      "source": [
        "## Project 2: Research Paper Analyst\n",
        "\n",
        "Make ChatGPT act as an AI expert and transform the given research paper abstract based on the nature of the audience mentioned below.\n",
        "\n",
        "- Short summary of maximum 10 lines for a general audience\n",
        "- Detailed report for a healthcare company. Have bullet points for pros and cons of ethics in Generative AI as mentioned in the paper\n",
        "- Detailed report for a generative AI company solving healthcare problems. Have bullet points for key points mentioned for Generative AI for text, images and structured data based healthcare\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjiheMsOMUO6"
      },
      "source": [
        "### Access the Research Paper Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4FnITE6zhV-9"
      },
      "outputs": [],
      "source": [
        "paper_abstract = f\"\"\"\n",
        "The widespread use of ChatGPT and other emerging technology powered by generative\n",
        "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
        "high-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\n",
        "issues beyond following guidelines and regulations that are still under discussion and\n",
        "development. On the other hand, other types of generative AI have been used to synthesize\n",
        "images and other types of data for research and practical purposes, which have resolved some\n",
        "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
        "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
        "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
        "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
        "transparent documentation of ethical discussions in generative AI development. While the\n",
        "checklist can be readily integrated into the current peer review and publication system to\n",
        "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
        "products) to help users establish reasonable trust in their capabilities.\n",
        "\n",
        "Current ethical discussions on generative AI in healthcare\n",
        "We conducted a systematic scoping review to analyse current ethical discussions on\n",
        "generative AI in healthcare. Our search in four major academic research databases for\n",
        "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
        "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
        "which 193 articles were included for analysis based on application data modality (text, image,\n",
        "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
        "AI causes or offers technical solutions for issues raised.\n",
        "\n",
        "Generative AI for text data-based healthcare\n",
        "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
        "applications for text data, with 20 articles describing methodological developments or\n",
        "applications of generative AI and the other 21 articles describing review-type works on this\n",
        "topic. Although some of these review-type articles used the general term “generative AI”, the\n",
        "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
        "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
        "ethical aspects.\n",
        "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
        "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
        "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
        "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
        "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
        "on the need for ethical considerations in LLMs and is summarised in the “Others” category.\n",
        "Although all ethical principles are equally important, some are discussed more often than\n",
        "others, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\n",
        "privacy.\n",
        "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
        "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
        "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
        "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
        "health-related misinformation, to generate trusted content, and to improve accountability or\n",
        "transparency over existing approaches. While most articles focused on either identifying\n",
        "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
        "articles discussed both to provide a more balanced perspective.\n",
        "\n",
        "Generative AI for image and structured data-based healthcare\n",
        "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
        "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
        "majority of articles discussed the methodological developments of generative AI as giving\n",
        "rise to a more distinctive and focused set of ethical issues.\n",
        "5\n",
        "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
        "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
        "brief motivation for methodological developments or as a general discussion point. The rest\n",
        "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
        "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
        "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
        "article24 discussed detailed ethical concerns on generative AI applications.\n",
        "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
        "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
        "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
        "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
        "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
        "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
        "additionally lacked discussions on trust or transparency.\n",
        "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
        "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
        "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
        "generative AI. Only two articles on structured data included both the cause and resolving\n",
        "perspectives by discussing ethical issues that may arise from limitations of methods\n",
        "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI2cwvpIMaGJ"
      },
      "source": [
        "### Create a prompt template for paper analysis and transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "E5S9fvwrYZ6u"
      },
      "outputs": [],
      "source": [
        "SYS_PROMPT = \"\"\"\n",
        "Act as a Artificial Intelligence Expert.\n",
        "Transform the input research paper abstract given below\n",
        "based on the instruction input by the user.\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        (\"human\", \"{instruction}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqEOQ4VZMfaC"
      },
      "source": [
        "### Create a simple LCEL LLM Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uc8fNUiXDUAC"
      },
      "outputs": [],
      "source": [
        "chain = (prompt\n",
        "            |\n",
        "         chatgpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2mbR5lfMkF8"
      },
      "source": [
        "### Generate the first summary report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "L8cgurf6Ytds"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "prompt_txt = f\"\"\"\n",
        "Based on the following research paper abstract,\n",
        "create the summary report of maximum 10 lines\n",
        "for a general audience\n",
        "\n",
        "Abstract:\n",
        "{paper_abstract}\n",
        "\"\"\"\n",
        "messages = [HumanMessage(content=prompt_txt)]\n",
        "user_instruction = {'instruction': messages}\n",
        "\n",
        "response = chain.invoke(user_instruction)\n",
        "messages.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVE4atsREzfp",
        "outputId": "27e78599-4d20-48aa-bc06-42db4785d079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The research paper explores the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The review analyzed 2,859 articles, focusing on ethical issues related to text, image, and structured data. While many articles addressed ethical concerns, there remains a lack of comprehensive discussions on autonomy and integrity. The proposed checklist could help users better understand and trust generative AI technologies.\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XYxJPOkdP9p",
        "outputId": "8e5b62ef-a768-409d-f415-67f35046ad29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term “generative AI”, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the “Others” category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='The research paper explores the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The review analyzed 2,859 articles, focusing on ethical issues related to text, image, and structured data. While many articles addressed ethical concerns, there remains a lack of comprehensive discussions on autonomy and integrity. The proposed checklist could help users better understand and trust generative AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 1320, 'total_tokens': 1459, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--fc8acc26-d5eb-4ea4-aea8-f5d90d335cee-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 139, 'total_tokens': 1459, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1V2RJQM_ry"
      },
      "source": [
        "### Generate the second summary report\n",
        "\n",
        "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "X_wqbVYOI42b"
      },
      "outputs": [],
      "source": [
        "prompt_txt = f\"\"\"\n",
        "Use only the research paper abstract from earlier and create a detailed report for a healthcare company.\n",
        "In the report, also include bullet points (3 max) for pros and cons of ethics in Generative AI\n",
        "\"\"\"\n",
        "messages.append(HumanMessage(content=prompt_txt))\n",
        "user_instruction = {'instruction': messages}\n",
        "response = chain.invoke(user_instruction)\n",
        "messages.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up-RtmIfFrAV",
        "outputId": "edff0155-05d6-4411-b57f-3f4e6dce4adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Detailed Report on Ethical Considerations in Generative AI for Healthcare**\n",
            "\n",
            "**Introduction:**\n",
            "The rapid adoption of generative artificial intelligence (AI) technologies, such as ChatGPT, has raised significant ethical concerns, particularly in high-stakes fields like healthcare. This report synthesizes findings from a systematic scoping review of existing literature on the ethical implications of generative AI in healthcare, highlighting gaps in current discussions and proposing a practical ethics checklist for developers and users.\n",
            "\n",
            "**Key Findings:**\n",
            "- **Ethical Gaps Identified:** The review analyzed 2,859 articles published between January 2013 and July 2023, focusing on ethical issues related to text, image, and structured data applications of generative AI. While many articles addressed ethical concerns, there was a notable lack of comprehensive discussions on critical issues such as autonomy and integrity.\n",
            "  \n",
            "- **Proposed Ethics Checklist:** To address these gaps, the report proposes an ethics checklist designed to enhance transparency and accountability in the development and application of generative AI technologies. This checklist can be integrated into existing peer review and publication processes, ensuring that ethical considerations are systematically documented and assessed.\n",
            "\n",
            "- **Diverse Applications and Ethical Issues:** The review categorized articles based on data modality (text, image, structured data) and found that while some articles focused on identifying ethical issues, others proposed generative AI-based solutions to mitigate these concerns. However, discussions on autonomy, integrity, and morality were often limited.\n",
            "\n",
            "**Pros and Cons of Ethics in Generative AI:**\n",
            "\n",
            "**Pros:**\n",
            "- **Enhanced Trust:** A robust ethical framework can foster user trust in generative AI technologies, ensuring that stakeholders feel confident in their applications.\n",
            "- **Improved Accountability:** Establishing clear ethical guidelines can hold developers accountable for the implications of their technologies, promoting responsible innovation.\n",
            "- **Comprehensive Assessment:** An ethics checklist allows for a thorough evaluation of generative AI applications, ensuring that ethical considerations are not overlooked.\n",
            "\n",
            "**Cons:**\n",
            "- **Complexity of Implementation:** Integrating ethical considerations into existing frameworks may complicate the development process and slow down innovation.\n",
            "- **Potential for Misinterpretation:** Ethical guidelines may be subject to varying interpretations, leading to inconsistent applications across different organizations.\n",
            "- **Resource Intensive:** Developing and maintaining an ethics checklist may require significant resources, which could be a barrier for smaller organizations.\n",
            "\n",
            "**Conclusion:**\n",
            "As generative AI technologies continue to evolve and integrate into healthcare, addressing ethical considerations is paramount. The proposed ethics checklist serves as a valuable tool for ensuring that ethical discussions are not only initiated but also documented and acted upon, ultimately leading to more responsible and trustworthy AI applications in healthcare.\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_wp-OBdxgh",
        "outputId": "f6fa5256-7130-4d35-b02c-d3157c1228a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate the summary report of maximum 10 lines\\nfor a general audience\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term “generative AI”, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the “Others” category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='The research paper explores the ethical implications of generative artificial intelligence (AI), particularly in healthcare settings. It highlights the growing use of technologies like ChatGPT and the need for clearer ethical guidelines as these tools become more prevalent. A systematic review of existing literature identified gaps in current ethical discussions, leading to the proposal of an ethics checklist. This checklist aims to enhance transparency and accountability in generative AI research and applications. The review analyzed 2,859 articles, focusing on ethical issues related to text, image, and structured data. While many articles addressed ethical concerns, there remains a lack of comprehensive discussions on autonomy and integrity. The proposed checklist could help users better understand and trust generative AI technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 1320, 'total_tokens': 1459, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--fc8acc26-d5eb-4ea4-aea8-f5d90d335cee-0', usage_metadata={'input_tokens': 1320, 'output_tokens': 139, 'total_tokens': 1459, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " HumanMessage(content='\\nUse only the research paper abstract from earlier and create a detailed report for a healthcare company.\\nIn the report, also include bullet points (3 max) for pros and cons of ethics in Generative AI\\n', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='**Detailed Report on Ethical Considerations in Generative AI for Healthcare**\\n\\n**Introduction:**\\nThe rapid adoption of generative artificial intelligence (AI) technologies, such as ChatGPT, has raised significant ethical concerns, particularly in high-stakes fields like healthcare. This report synthesizes findings from a systematic scoping review of existing literature on the ethical implications of generative AI in healthcare, highlighting gaps in current discussions and proposing a practical ethics checklist for developers and users.\\n\\n**Key Findings:**\\n- **Ethical Gaps Identified:** The review analyzed 2,859 articles published between January 2013 and July 2023, focusing on ethical issues related to text, image, and structured data applications of generative AI. While many articles addressed ethical concerns, there was a notable lack of comprehensive discussions on critical issues such as autonomy and integrity.\\n  \\n- **Proposed Ethics Checklist:** To address these gaps, the report proposes an ethics checklist designed to enhance transparency and accountability in the development and application of generative AI technologies. This checklist can be integrated into existing peer review and publication processes, ensuring that ethical considerations are systematically documented and assessed.\\n\\n- **Diverse Applications and Ethical Issues:** The review categorized articles based on data modality (text, image, structured data) and found that while some articles focused on identifying ethical issues, others proposed generative AI-based solutions to mitigate these concerns. However, discussions on autonomy, integrity, and morality were often limited.\\n\\n**Pros and Cons of Ethics in Generative AI:**\\n\\n**Pros:**\\n- **Enhanced Trust:** A robust ethical framework can foster user trust in generative AI technologies, ensuring that stakeholders feel confident in their applications.\\n- **Improved Accountability:** Establishing clear ethical guidelines can hold developers accountable for the implications of their technologies, promoting responsible innovation.\\n- **Comprehensive Assessment:** An ethics checklist allows for a thorough evaluation of generative AI applications, ensuring that ethical considerations are not overlooked.\\n\\n**Cons:**\\n- **Complexity of Implementation:** Integrating ethical considerations into existing frameworks may complicate the development process and slow down innovation.\\n- **Potential for Misinterpretation:** Ethical guidelines may be subject to varying interpretations, leading to inconsistent applications across different organizations.\\n- **Resource Intensive:** Developing and maintaining an ethics checklist may require significant resources, which could be a barrier for smaller organizations.\\n\\n**Conclusion:**\\nAs generative AI technologies continue to evolve and integrate into healthcare, addressing ethical considerations is paramount. The proposed ethics checklist serves as a valuable tool for ensuring that ethical discussions are not only initiated but also documented and acted upon, ultimately leading to more responsible and trustworthy AI applications in healthcare.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 528, 'prompt_tokens': 1749, 'total_tokens': 2277, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, id='run--944d4096-c445-4123-b28a-5774e2195db8-0', usage_metadata={'input_tokens': 1749, 'output_tokens': 528, 'total_tokens': 2277, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS2PGF6DNMky"
      },
      "source": [
        "### Generate the third summary report\n",
        "\n",
        "Here we add the previous LLM response and the new instructions to the list of messages and send the whole thing to the LLM so it has access to the historical conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lD6sIrMVJrRx"
      },
      "outputs": [],
      "source": [
        "prompt_txt = f\"\"\"\n",
        "Use only the research paper abstract from earlier and create a detailed report for a generative AI company solving healthcare problems.\n",
        "In the report also include sections for key points mentioned around Generative AI for text, images and structured data based healthcare\n",
        "\"\"\"\n",
        "messages.append(HumanMessage(content=prompt_txt))\n",
        "user_instruction = {'instruction': messages}\n",
        "response = chain.invoke(user_instruction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUjMVo63eZit",
        "outputId": "20ac8116-301f-4340-ebf8-64a11756d5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Detailed Report on Ethical Considerations in Generative AI for Healthcare**\n",
            "\n",
            "**Introduction:**\n",
            "The increasing integration of generative artificial intelligence (AI) technologies, such as ChatGPT, into healthcare has sparked significant ethical discussions. This report synthesizes findings from a systematic scoping review of existing literature on the ethical implications of generative AI in healthcare, identifying gaps in current discussions and proposing a practical ethics checklist for developers and users.\n",
            "\n",
            "**Key Findings:**\n",
            "- **Ethical Gaps Identified:** The review analyzed 2,859 articles published between January 2013 and July 2023, focusing on ethical issues related to text, image, and structured data applications of generative AI. While many articles addressed ethical concerns, there was a notable lack of comprehensive discussions on critical issues such as autonomy and integrity.\n",
            "\n",
            "- **Proposed Ethics Checklist:** To address these gaps, the report proposes an ethics checklist designed to enhance transparency and accountability in the development and application of generative AI technologies. This checklist can be integrated into existing peer review and publication processes, ensuring that ethical considerations are systematically documented and assessed.\n",
            "\n",
            "- **Diverse Applications and Ethical Issues:** The review categorized articles based on data modality (text, image, structured data) and found that while some articles focused on identifying ethical issues, others proposed generative AI-based solutions to mitigate these concerns. However, discussions on autonomy, integrity, and morality were often limited.\n",
            "\n",
            "**Generative AI for Text Data in Healthcare:**\n",
            "- **Ethical Considerations:** Among the 193 articles analyzed, 41 focused on generative AI applications for text data. These articles discussed various ethical issues, particularly those related to large language models (LLMs) like GPT. Key concerns included non-maleficence, equity, and privacy.\n",
            "- **Proposed Solutions:** Some articles aimed to resolve ethical issues, such as confidentiality of medical data, by using LLMs to generate synthetic medical text, thereby addressing privacy concerns and improving accessibility.\n",
            "\n",
            "**Generative AI for Image Data in Healthcare:**\n",
            "- **Ethical Considerations:** The review identified 98 articles discussing generative AI applications for image data. Many of these articles briefly mentioned ethical considerations, primarily focusing on methodological developments rather than in-depth ethical discussions.\n",
            "- **Proposed Solutions:** A significant number of articles aimed to resolve privacy issues by generating synthetic data, with some addressing bias in datasets to ensure representation of under-represented subgroups.\n",
            "\n",
            "**Generative AI for Structured Data in Healthcare:**\n",
            "- **Ethical Considerations:** The review included 58 articles on structured data, where ethical discussions were even less prevalent. Most articles mentioned ethical considerations only briefly, lacking comprehensive discussions on autonomy, integrity, or morality.\n",
            "- **Proposed Solutions:** Similar to image data, many articles focused on resolving privacy issues through data synthesis, but discussions on trust and transparency were notably absent.\n",
            "\n",
            "**Conclusion:**\n",
            "As generative AI technologies continue to evolve and integrate into healthcare, addressing ethical considerations is paramount. The proposed ethics checklist serves as a valuable tool for ensuring that ethical discussions are not only initiated but also documented and acted upon, ultimately leading to more responsible and trustworthy AI applications in healthcare. By focusing on the ethical implications of generative AI across text, image, and structured data, companies can better navigate the complexities of ethical AI deployment in healthcare settings.\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX8i7Yg2NS9F"
      },
      "source": [
        "## Mini-Project 3: Social Media Marketing Analyst\n",
        "\n",
        "You have the technical fact sheets of one smartphone. Try some iterative prompt engineering and do the following:\n",
        "\n",
        "1. Generate marketing product description for the smartphone\n",
        "\n",
        "2. Custom product description which has the following:\n",
        "\n",
        "```\n",
        "The description should follow this format:\n",
        "\n",
        "Product Name: <Name of the smartphone>\n",
        "​\n",
        "Description: <Brief Overview of the features>\n",
        "​\n",
        "Product Specifications:\n",
        "<Table with key product feature specifications>\n",
        "​\n",
        "The description should focus on the most important features\n",
        "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
        "​\n",
        "After the description, the table should have the\n",
        "key specifications of the product. It should have two columns.\n",
        "The first column should have 'Feature'\n",
        "and the second column should have 'Specification'\n",
        "and try to put exact numeric values for features if they exist.\n",
        "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
        "```\n",
        "\n",
        "3. Custom product description focusing on specific aspects like display, camera and in less than 60 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmADan2jQmWt"
      },
      "source": [
        "### Access the product factsheet data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tyaP_Ab_L9c5"
      },
      "outputs": [],
      "source": [
        "fact_sheet_mobile = \"\"\"\n",
        "PRODUCT NAME\n",
        "Samsung Galaxy Z Fold4 5G Black\n",
        "​\n",
        "PRODUCT OVERVIEW\n",
        "Stands out. Stands up. Unfolds.\n",
        "The Galaxy Z Fold4 does a lot in one hand with its 15.73 cm(6.2-inch) Cover Screen.\n",
        "Unfolded, the 19.21 cm(7.6-inch) Main Screen lets you really get into the zone.\n",
        "Pushed-back bezels and the Under Display Camera means there's more screen\n",
        "and no black dot getting between you and the breathtaking Infinity Flex Display.\n",
        "Do more than more with Multi View. Whether toggling between texts or catching up\n",
        "on emails, take full advantage of the expansive Main Screen with Multi View.\n",
        "PC-like power thanks to Qualcomm Snapdragon 8+ Gen 1 processor in your pocket,\n",
        "transforms apps optimized with One UI to give you menus and more in a glance\n",
        "New Taskbar for PC-like multitasking. Wipe out tasks in fewer taps. Add\n",
        "apps to the Taskbar for quick navigation and bouncing between windows when\n",
        "you're in the groove.4 And with App Pair, one tap launches up to three apps,\n",
        "all sharing one super-productive screen\n",
        "Our toughest Samsung Galaxy foldables ever. From the inside out,\n",
        "Galaxy Z Fold4 is made with materials that are not only stunning,\n",
        "but stand up to life's bumps and fumbles. The front and rear panels,\n",
        "made with exclusive Corning Gorilla Glass Victus+, are ready to resist\n",
        "sneaky scrapes and scratches. With our toughest aluminum frame made with\n",
        "Armor Aluminum, this is one durable smartphone.\n",
        "World’s first water resistant foldable smartphones. Be adventurous, rain\n",
        "or shine. You don't have to sweat the forecast when you've got one of the\n",
        "world's first water-resistant foldable smartphones.\n",
        "​\n",
        "PRODUCT SPECS\n",
        "OS - Android 12.0\n",
        "RAM - 12 GB\n",
        "Product Dimensions - 15.5 x 13 x 0.6 cm; 263 Grams\n",
        "Batteries - 2 Lithium Ion batteries required. (included)\n",
        "Item model number - SM-F936BZKDINU_5\n",
        "Wireless communication technologies - Cellular\n",
        "Connectivity technologies - Bluetooth, Wi-Fi, USB, NFC\n",
        "GPS - True\n",
        "Special features - Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, Water Resistant\n",
        "Other display features - Wireless\n",
        "Device interface - primary - Touchscreen\n",
        "Resolution - 2176x1812\n",
        "Other camera features - Rear, Front\n",
        "Form factor - Foldable Screen\n",
        "Colour - Phantom Black\n",
        "Battery Power Rating - 4400\n",
        "Whats in the box - SIM Tray Ejector, USB Cable\n",
        "Manufacturer - Samsung India pvt Ltd\n",
        "Country of Origin - China\n",
        "Item Weight - 263 g\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "didH1ICSQrX0"
      },
      "source": [
        "### Create prompt template for the first advert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2EJ2PPzJN3U5"
      },
      "outputs": [],
      "source": [
        "prompt_txt = \"\"\"\n",
        "Act as a marketing manager.\n",
        "Your task is to help a marketing team create a\n",
        "description for a retail website advert of a product based\n",
        "on a technical fact sheet specifications for a mobile smartphone\n",
        "​\n",
        "Write a brief product description\n",
        "\n",
        "Technical specifications:\n",
        "{fact_sheet_mobile}\n",
        "\"\"\"\n",
        "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq1SXWSBQuzJ"
      },
      "source": [
        "### Use an LCEL LLM Chain to generate the first advert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Shlyf_lxOo1E"
      },
      "outputs": [],
      "source": [
        "chain = (chat_template\n",
        "            |\n",
        "         chatgpt)\n",
        "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGlB6xteO-FP",
        "outputId": "b36fe794-873b-4c3d-da3c-d483c5e9072d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Product Description: Samsung Galaxy Z Fold4 5G - Phantom Black**\n",
            "\n",
            "Unleash the power of innovation with the Samsung Galaxy Z Fold4 5G in stunning Phantom Black. This groundbreaking foldable smartphone is designed to elevate your mobile experience, seamlessly blending style and functionality. \n",
            "\n",
            "**Stand Out, Stand Up, Unfold:** With a compact 6.2-inch Cover Screen, you can easily navigate your day-to-day tasks with one hand. When it’s time to dive deeper, unfold the device to reveal a breathtaking 7.6-inch Main Screen, featuring an Infinity Flex Display that maximizes your viewing area while minimizing distractions. \n",
            "\n",
            "**Multitasking Made Easy:** Experience PC-like power with the Qualcomm Snapdragon 8+ Gen 1 processor and the new Taskbar feature, allowing you to switch between apps effortlessly. With Multi View and App Pair, you can run up to three apps simultaneously, making productivity a breeze.\n",
            "\n",
            "**Durability Meets Elegance:** Crafted with exclusive Corning Gorilla Glass Victus+ and Armor Aluminum, the Galaxy Z Fold4 is built to withstand life’s little accidents. Plus, it’s one of the world’s first water-resistant foldable smartphones, so you can embrace adventure without worry, rain or shine.\n",
            "\n",
            "**Advanced Features:** Running on Android 12.0 with 12 GB of RAM, this device is equipped with fast charging support, dual SIM capabilities, and built-in GPS. The 4400 mAh battery ensures you stay powered throughout your day, while the sleek design and lightweight build (just 263 grams) make it a perfect fit for your lifestyle.\n",
            "\n",
            "**What’s in the Box:** Your purchase includes a SIM Tray Ejector and USB Cable, so you’re ready to go right out of the box.\n",
            "\n",
            "Elevate your mobile experience with the Samsung Galaxy Z Fold4 5G – where cutting-edge technology meets sophisticated design. Get yours today and redefine what a smartphone can do!\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "jPE1vZuTPgJs",
        "outputId": "c2f3fab9-df47-4d5d-be74-cde327060d23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Product Description: Samsung Galaxy Z Fold4 5G - Phantom Black**\n\nUnleash the power of innovation with the Samsung Galaxy Z Fold4 5G in stunning Phantom Black. This groundbreaking foldable smartphone is designed to elevate your mobile experience, seamlessly blending style and functionality. \n\n**Stand Out, Stand Up, Unfold:** With a compact 6.2-inch Cover Screen, you can easily navigate your day-to-day tasks with one hand. When it’s time to dive deeper, unfold the device to reveal a breathtaking 7.6-inch Main Screen, featuring an Infinity Flex Display that maximizes your viewing area while minimizing distractions. \n\n**Multitasking Made Easy:** Experience PC-like power with the Qualcomm Snapdragon 8+ Gen 1 processor and the new Taskbar feature, allowing you to switch between apps effortlessly. With Multi View and App Pair, you can run up to three apps simultaneously, making productivity a breeze.\n\n**Durability Meets Elegance:** Crafted with exclusive Corning Gorilla Glass Victus+ and Armor Aluminum, the Galaxy Z Fold4 is built to withstand life’s little accidents. Plus, it’s one of the world’s first water-resistant foldable smartphones, so you can embrace adventure without worry, rain or shine.\n\n**Advanced Features:** Running on Android 12.0 with 12 GB of RAM, this device is equipped with fast charging support, dual SIM capabilities, and built-in GPS. The 4400 mAh battery ensures you stay powered throughout your day, while the sleek design and lightweight build (just 263 grams) make it a perfect fit for your lifestyle.\n\n**What’s in the Box:** Your purchase includes a SIM Tray Ejector and USB Cable, so you’re ready to go right out of the box.\n\nElevate your mobile experience with the Samsung Galaxy Z Fold4 5G – where cutting-edge technology meets sophisticated design. Get yours today and redefine what a smartphone can do!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqNQsEWPQ3qz"
      },
      "source": [
        "### Create prompt template for the second advert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "j-CsFl0FPA9z"
      },
      "outputs": [],
      "source": [
        "prompt_txt = \"\"\"\n",
        "Act as a marketing manager.\n",
        "Your task is to help a marketing team create a\n",
        "description for a retail website advert of a product based\n",
        "on a technical fact sheet specifications for a mobile smartphone\n",
        "​\n",
        "The description should follow this format:\n",
        "\n",
        "Product Name: <Name of the smartphone>\n",
        "​\n",
        "Description: <Brief Overview of the features>\n",
        "​\n",
        "Product Specifications:\n",
        "<Table with key product feature specifications>\n",
        "​\n",
        "The description should focus on the most important features\n",
        "a customer might look for in a phone including the foldable display screen, processing power, RAM, camera and battery life.\n",
        "​\n",
        "After the description, the table should have the\n",
        "key specifications of the product. It should have two columns.\n",
        "The first column should have 'Feature'\n",
        "and the second column should have 'Specification'\n",
        "and try to put exact numeric values for features if they exist.\n",
        "Only put these features in the table - foldable display screen, processing power, RAM, camera and battery life\n",
        "\n",
        "Technical specifications:\n",
        "{fact_sheet_mobile}\n",
        "\"\"\"\n",
        "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6EmK1TkRADG"
      },
      "source": [
        "### Use an LCEL LLM Chain to generate the second advert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "uievnu1GPSgj"
      },
      "outputs": [],
      "source": [
        "chain = (chat_template\n",
        "            |\n",
        "         chatgpt)\n",
        "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fY4nEK3PUbU",
        "outputId": "4a1cd90c-c1e3-4d2e-b86b-027fd05c0e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Product Name:** Samsung Galaxy Z Fold4 5G Black\n",
            "\n",
            "**Description:**  \n",
            "Experience the future of mobile technology with the Samsung Galaxy Z Fold4 5G. This innovative smartphone features a stunning 7.6-inch Main Screen that unfolds to provide an immersive viewing experience, while the 6.2-inch Cover Screen allows for quick access to notifications and apps. Powered by the Qualcomm Snapdragon 8+ Gen 1 processor and equipped with 12 GB of RAM, multitasking has never been smoother. Capture breathtaking photos with its advanced camera system, and enjoy all-day usage with a robust 4400 mAh battery. Plus, with its water-resistant design and durable materials, the Galaxy Z Fold4 is built to withstand life's adventures.\n",
            "\n",
            "**Product Specifications:**\n",
            "\n",
            "| Feature                | Specification          |\n",
            "|-----------------------|------------------------|\n",
            "| Foldable Display Screen| 7.6 inches (Main), 6.2 inches (Cover) |\n",
            "| Processing Power       | Qualcomm Snapdragon 8+ Gen 1 |\n",
            "| RAM                    | 12 GB                  |\n",
            "| Camera                 | Rear: Triple Camera, Front: 10 MP |\n",
            "| Battery Life           | 4400 mAh               |\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "dsBjspPgPWX7",
        "outputId": "d2c1c826-0975-467a-d765-e62fe83b9275"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Product Name:** Samsung Galaxy Z Fold4 5G Black\n\n**Description:**  \nExperience the future of mobile technology with the Samsung Galaxy Z Fold4 5G. This innovative smartphone features a stunning 7.6-inch Main Screen that unfolds to provide an immersive viewing experience, while the 6.2-inch Cover Screen allows for quick access to notifications and apps. Powered by the Qualcomm Snapdragon 8+ Gen 1 processor and equipped with 12 GB of RAM, multitasking has never been smoother. Capture breathtaking photos with its advanced camera system, and enjoy all-day usage with a robust 4400 mAh battery. Plus, with its water-resistant design and durable materials, the Galaxy Z Fold4 is built to withstand life's adventures.\n\n**Product Specifications:**\n\n| Feature                | Specification          |\n|-----------------------|------------------------|\n| Foldable Display Screen| 7.6 inches (Main), 6.2 inches (Cover) |\n| Processing Power       | Qualcomm Snapdragon 8+ Gen 1 |\n| RAM                    | 12 GB                  |\n| Camera                 | Rear: Triple Camera, Front: 10 MP |\n| Battery Life           | 4400 mAh               |"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPytTJ6KQ50L"
      },
      "source": [
        "### Create prompt template for the third advert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1nB4OZp0PcN6"
      },
      "outputs": [],
      "source": [
        "prompt_txt = \"\"\"\n",
        "Act as a marketing manager.\n",
        "Your task is to help a marketing team create a\n",
        "description for a retail website advert of a product based\n",
        "on a technical fact sheet specifications for a mobile smartphone\n",
        "​\n",
        "Write a catchy product description with some emojis,\n",
        "which uses at most 60 words\n",
        "and focuses on the most important things about the smartphone\n",
        "which might matter to users like display and camera\n",
        "\n",
        "Technical specifications:\n",
        "{fact_sheet_mobile}\n",
        "\"\"\"\n",
        "chat_template = ChatPromptTemplate.from_template(prompt_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wKXMaZbRCxO"
      },
      "source": [
        "### Use an LCEL LLM Chain to generate the third advert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hDAYappnQXN4"
      },
      "outputs": [],
      "source": [
        "chain = (chat_template\n",
        "            |\n",
        "         chatgpt)\n",
        "response = chain.invoke({\"fact_sheet_mobile\": fact_sheet_mobile})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_QMf99GQZZo",
        "outputId": "cc51cb7a-daa7-4b96-f354-78a78371bba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌟 Unfold a new world with the Samsung Galaxy Z Fold4 5G! 📱✨ Experience stunning visuals on a 7.6-inch Infinity Flex Display and capture every moment with its advanced camera system. With lightning-fast performance and water resistance, this foldable powerhouse is built for adventure. Elevate your multitasking game with the new Taskbar! 🚀💧 #SamsungGalaxyZFold4\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "tc7LJylgQa9j",
        "outputId": "4e5f5559-21e9-49dc-88d8-75c685a2950a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "🌟 Unfold a new world with the Samsung Galaxy Z Fold4 5G! 📱✨ Experience stunning visuals on a 7.6-inch Infinity Flex Display and capture every moment with its advanced camera system. With lightning-fast performance and water resistance, this foldable powerhouse is built for adventure. Elevate your multitasking game with the new Taskbar! 🚀💧 #SamsungGalaxyZFold4"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGvqHtrZRqTs"
      },
      "source": [
        "## Project 4 - IT Support Analyst\n",
        "\n",
        "Ask ChatGPT to act as a IT support agent, process each customer IT ticket message and output the response in JSON with the following fields\n",
        "\n",
        "```\n",
        "orig_msg: The original customer message\n",
        "orig_lang: Detected language of the customer message e.g. Spanish\n",
        "category: 1-2 word describing the category of the problem\n",
        "trans_msg: Translated customer message in English\n",
        "response: Response to the customer in orig_lang\n",
        "trans_response: Response to the customer in English\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g40fksfTNpQ"
      },
      "source": [
        "### Define Output Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "F7yEig9NRvsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63bdeb62-0a97-4038-e02e-64ad60c68904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "\n",
        "# Define your desired data structure - like a python data class.\n",
        "class ITSupportResponse(BaseModel):\n",
        "    orig_msg: str = Field(description=\"The original customer IT support query message\")\n",
        "    orig_lang: str = Field(description=\"Detected language of the customer message e.g. Spanish\")\n",
        "    category: str = Field(description=\"1-2 word describing the category of the problem\")\n",
        "    trans_msg: str = Field(description=\"Translated customer IT support query message in English\")\n",
        "    response: str = Field(description=\"Response to the customer in their original language - orig_lang\")\n",
        "    trans_response: str = Field(description=\"Response to the customer in English\")\n",
        "\n",
        "\n",
        "parser = JsonOutputParser(pydantic_object=ITSupportResponse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEQL4DhYTZug"
      },
      "source": [
        "### Create the input prompt for the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "XbT3tGUUSIct"
      },
      "outputs": [],
      "source": [
        "# create the final prompt with formatting instructions from the parser\n",
        "prompt_txt = \"\"\"\n",
        "             Act as an Information Technology (IT) customer support agent.\n",
        "             For the IT support message mentioned below\n",
        "             use the following output format when generating the output response\n",
        "\n",
        "             Output format instructions:\n",
        "             {format_instructions}\n",
        "\n",
        "             Customer IT support message:\n",
        "             {it_support_msg}\n",
        "             \"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_txt,\n",
        "    input_variables=[\"it_support_msg\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMA7qY1XTeeR"
      },
      "source": [
        "### Create a LCEL LLM Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Le18crwjSnY_"
      },
      "outputs": [],
      "source": [
        "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
        "llm_chain = (prompt\n",
        "              |\n",
        "            chatgpt\n",
        "              |\n",
        "            parser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li4TbuTGTj2H"
      },
      "source": [
        "### Access Customer IT Support ticket data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdlcULKISsC2",
        "outputId": "358464f0-ed53-4c9b-dae4-6007d5b1d031"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'it_support_msg': 'Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "it_support_queue = [\n",
        "    \"Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.\",\n",
        "    \"Ho problemi a stampare i documenti da remoto. Il lavoro non viene inviato alla stampante di rete.\",\n",
        "    \"プリンターのトナーを交換しましたが、印刷品質が低下しています。サポートが必要です。\",\n",
        "    \"Я не могу войти в систему учета времени, появляется сообщение об ошибке. Мне нужна помощь.\",\n",
        "    \"Internet bağlantım çok yavaş ve bazen tamamen kesiliyor. Yardım eder misiniz?\",\n",
        "    \"Не могу установить обновление безопасности. Появляется код ошибки. Помогите, пожалуйста.\"\n",
        "]\n",
        "\n",
        "formatted_msgs = [{\"it_support_msg\": msg}\n",
        "                    for msg in it_support_queue]\n",
        "formatted_msgs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuTYg0GyTtei"
      },
      "source": [
        "### Get responses from the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "adEaXYtsSxWa"
      },
      "outputs": [],
      "source": [
        "responses = llm_chain.map().invoke(formatted_msgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iVZrIqITu3j"
      },
      "source": [
        "### View LLM responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgbcB5K7S3z0",
        "outputId": "fc1cea4d-17a8-40d2-a4b3-6634096ff943"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'orig_msg': 'Não consigo sincronizar meus contatos com o telefone. Sempre recebo uma mensagem de falha.',\n",
              " 'orig_lang': 'Portuguese',\n",
              " 'category': 'Sync Issue',\n",
              " 'trans_msg': 'I cannot sync my contacts with the phone. I always receive a failure message.',\n",
              " 'response': 'Por favor, verifique se você está conectado à internet e tente reiniciar o telefone. Se o problema persistir, considere desinstalar e reinstalar o aplicativo de contatos.',\n",
              " 'trans_response': 'Please check if you are connected to the internet and try restarting the phone. If the problem persists, consider uninstalling and reinstalling the contacts app.'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "responses[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9U5mhraS65l",
        "outputId": "1b131fcf-a61a-4f46-d1c1-9730fde7cdb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "type(responses[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}