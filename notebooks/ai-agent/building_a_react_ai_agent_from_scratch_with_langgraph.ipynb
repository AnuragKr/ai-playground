{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pdRDlVs1MJs"
      },
      "source": [
        "# Building a ReAct AI Agent from scratch with LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBpZTjLnEXb"
      },
      "source": [
        "Here we will build AI Agents with LangGraph from scratch.\n",
        "\n",
        "Here we'll create a simple ReAct agent app that can search the web and check the weather. The app consists of an agent (LLM) and tools. As we interact with the app, we will first call the agent (LLM) to decide if we should use tools. Then we will run a loop:\n",
        "\n",
        "- If the agent said to take an action (i.e. call tool), we'll run the tools and pass the results back to the agent\n",
        "- If the agent did not ask to run tools, we will finish (respond to the user)\n",
        "\n",
        "We will implement this in LangGraph completely from scratch step by step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ0q3K8Y1TCf"
      },
      "source": [
        "There will be three parts to this hands-on demo:\n",
        "\n",
        "- Part I: Build a Basic Chatbot with LangGraph\n",
        "- Part II: Build a simple ReAct Agent with LangGraph - LLM + Tools\n",
        "- Part III: Build a multi-user conversational ReAct Agent with LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6bDqJFpHDWD"
      },
      "source": [
        "Install the following httpx library version for compatibility with other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87n3wLCfHDWD",
        "outputId": "cd4cb95d-9c1b-4509-a697-11a843ba31c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.16.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx==0.27.2) (4.13.2)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.16.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed httpx-0.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install httpx==0.27.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "6e2aaa42-5052-446f-806e-1cbb68637ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.2.0\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.2.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
            "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1 (from langchain==0.2.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.0) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: tenacity, numpy, mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.42\n",
            "    Uninstalling langsmith-0.3.42:\n",
            "      Successfully uninstalled langsmith-0.3.42\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.60\n",
            "    Uninstalling langchain-core-0.3.60:\n",
            "      Successfully uninstalled langchain-core-0.3.60\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.8\n",
            "    Uninstalling langchain-text-splitters-0.3.8:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-0.2.0 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.147 marshmallow-3.26.1 mypy-extensions-1.1.0 numpy-1.26.4 tenacity-8.5.0 typing-inspect-0.9.0\n",
            "Collecting langchain-openai==0.1.7\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (0.2.43)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (1.81.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (0.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.11.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (4.13.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.4.0)\n",
            "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.1.7\n",
            "Collecting langchain-community==0.2.0\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.43)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.2.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.0) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.4.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (1.1.0)\n",
            "Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-community\n",
            "Successfully installed langchain-community-0.2.0\n",
            "Collecting langgraph==0.1.1\n",
            "  Downloading langgraph-0.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.1.1) (0.2.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.11.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.4.0)\n",
            "Downloading langgraph-0.1.1-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph\n",
            "Successfully installed langgraph-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.2.0\n",
        "!pip install langchain-openai==0.1.7\n",
        "!pip install langchain-community==0.2.0\n",
        "!pip install langgraph==0.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "WEATHER_API_KEY = userdata.get('WEATHER_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef7bcad1-1274-4b7c-a2e9-365180ef3a31"
      },
      "source": [
        "## Part I: Build a Basic Chatbot with LangGraph\n",
        "\n",
        "The first step will be to create a simple chatbot using LangGraph.\n",
        "\n",
        "This chatbot will respond directly to user messages.\n",
        "\n",
        "- We will start by creating a `StateGraph`. A `StateGraph` object defines the structure of our chatbot as a \"state machine\"\n",
        "- `nodes` will represent the llm and functions our chatbot can call\n",
        "- `edges` will specify how the bot should transition between these functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MbYwaKHaaMaw"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\"\n",
        "    # The `add_messages` function in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4137feed-746e-4c72-a34a-f7a699ad5dcf"
      },
      "source": [
        "We've defined our `State` as a TypedDict with a single key: `messages`.\n",
        "\n",
        "The `messages` key is annotated with the [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function, which tells LangGraph to append new messages to the existing list, rather than overwriting it.\n",
        "\n",
        "So now our graph knows two things:\n",
        "\n",
        "1. Every `node` we define will receive the current `State` as input and return a value that updates that state.\n",
        "2. `messages` will be _appended_ to the current list, rather than directly overwritten. This is communicated via the prebuilt [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function in the `Annotated` syntax.\n",
        "\n",
        "Next, we add a \"`chatbot`\" node.\n",
        "\n",
        "Nodes represent units of work. They are typically regular python functions.\n",
        "\n",
        "This is a simple node which will just send our messages to an LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ETuxgmRjaMk_"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [chatgpt.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object\n",
        "# this function will be called whenever the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6c1dcd9-fb86-4649-81b4-ff6ce20a2e46"
      },
      "source": [
        "The `chatbot` node function takes the current `State` as input and returns an updated `messages` list.\n",
        "\n",
        "This is the basic pattern for all LangGraph node functions.\n",
        "\n",
        "The `add_messages` function in our `State` will append the LLM's response messages to whatever messages are already in the state.\n",
        "\n",
        "Next, we add an `entry` point. This tells our graph **where to start its work** each time we run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tqVRB_2CaMng"
      },
      "outputs": [],
      "source": [
        "graph_builder.set_entry_point(\"chatbot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0499c318-d1e6-46fa-a652-8f9e65313355"
      },
      "source": [
        "Similarly, we set a `finish` point. This instructs the graph **\"any time this node is run, you can exit.\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XjuYxBaZaMqE"
      },
      "outputs": [],
      "source": [
        "graph_builder.set_finish_point(\"chatbot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65a9b88c-2c53-4d95-8eb1-d544a8946f65"
      },
      "source": [
        "Now we will compile our graph by calling \"`compile()`\" on the graph builder.\n",
        "\n",
        "This creates a \"`CompiledGraph`\" we can use invoke on our state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AKydEtVUjZl_"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "t2tFRI5JjaTS",
        "outputId": "28622220-a07c-421a-ffdb-6aa7f9494b8b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JdGjoZP4jeNB"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"What is the fastest animal on land?\"\"\"\n",
        "response = graph.invoke({\"messages\": (\"user\", prompt)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmzvlzV_j1Ey",
        "outputId": "5dcf689b-0063-488c-f426-e924ea99a418"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is the fastest animal on land?', id='579b627f-23e8-4d9f-81d1-18e5c318d096'),\n",
              "  AIMessage(content='The fastest animal on land is the cheetah. It can reach speeds of up to 60 to 70 miles per hour (97 to 113 kilometers per hour) in short bursts covering distances up to 1,500 feet (460 meters), and it can accelerate from 0 to 60 miles per hour in just a few seconds.', response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 15, 'total_tokens': 85, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-9f84acae-da3d-4940-8f40-f7cdee66e737-0')]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "_sHjXmwij9wT",
        "outputId": "abdeda8c-2fc7-4876-b799-b9edcd76b03d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Langraph is a platform designed to facilitate the creation and deployment of AI applications using large language models (LLMs). It provides tools and infrastructure that allow developers to build, test, and manage applications that leverage the capabilities of LLMs. Langraph aims to simplify the process of integrating advanced language models into various applications, making it accessible for developers to harness the power of AI in their projects. The platform may offer features such as API access, model training, and deployment options, as well as tools for monitoring and optimizing the performance of language models in real-world applications."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"What is langraph?\"\"\"\n",
        "response = graph.invoke({\"messages\": (\"user\", prompt)})\n",
        "display(Markdown(response['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKQdaFnikWWl",
        "outputId": "c952c0e8-f754-46c2-8677-00ceb77a85d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is langraph?', id='8906ef10-ca53-4562-837b-00a5f6addebb'),\n",
              "  AIMessage(content='Langraph is a platform designed to facilitate the creation and deployment of AI applications using large language models (LLMs). It provides tools and infrastructure that allow developers to build, test, and manage applications that leverage the capabilities of LLMs. Langraph aims to simplify the process of integrating advanced language models into various applications, making it accessible for developers to harness the power of AI in their projects. The platform may offer features such as API access, model training, and deployment options, as well as tools for monitoring and optimizing the performance of language models in real-world applications.', response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 12, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_a288987b44', 'finish_reason': 'stop', 'logprobs': None}, id='run-f609738e-fe49-4357-b3b8-02d01064645a-0')]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvMcvpTckdIn"
      },
      "source": [
        "We have built a simple chatbot using LangGraph.\n",
        "\n",
        "This bot can engage in basic conversation by taking user input and generating responses using an LLM. However it cannot give responses to recent information, here we will enhance it with some tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZtBIOEbllRg"
      },
      "source": [
        "## Part II: Build a simple ReAct Agent with LangGraph - LLM + Tools\n",
        "\n",
        "Now, we will build a simple ReAct agent in LangGraph which will use the web search or weather tool based on our input prompts to get relevant data which the LLM might not know by default and give relevant responses\n",
        "\n",
        "We will showcase the following:\n",
        "\n",
        "1. Building the agent completely from scratch\n",
        "2. Leveraging LangGraph built-in node functions to build the agent faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "howf-v0ARWbv"
      },
      "source": [
        "### Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Simple Web Search tool\n",
        "- Weather tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ue8xgu9WpuPi"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "import json\n",
        "import requests\n",
        "\n",
        "tv_search = TavilySearchResults(max_results=3, search_depth='advanced',\n",
        "                                max_tokens=10000)\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web for a query.\"\"\"\n",
        "    results = tv_search.invoke(query)\n",
        "    return results\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather.\"\"\"\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5GgBmO3mK8N"
      },
      "source": [
        "### Build the Agentic Graph from Scratch\n",
        "\n",
        "Here we will use LangGraph to build the full graph which will have the Agentic workflow.\n",
        "\n",
        "Each functionality will be implemented from scrach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GRcmnlw4mSaF"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "# Tell the LLM which tools it can call\n",
        "tools = [search_web, get_weather]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1e84cfc-b1b2-48e3-8550-152a408c3926"
      },
      "source": [
        "We will now need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node.\n",
        "\n",
        "We implement a `BasicToolNode` that checks the most recent message in the state and calls tools if the message contains `tool_calls`.\n",
        "\n",
        "It relies on the LLM's `tool_calling` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\n",
        "\n",
        "We will later replace this with LangGraph's prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) to speed things up, but building it from scratch gives us an idea of what happens under the hood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "neog5XwvnNNx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools} # => {'search_web': search_web, 'get_weather': get_weather}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1] # get most recent message\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        # if tool calls are mentioned by LLM in the most recent message\n",
        "        # call the tool and get the result\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "# add tool node to graph\n",
        "tool_node = BasicToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b049afc4-7757-40ba-8e00-589d378e816d"
      },
      "source": [
        "With the tool node added, we can define the `conditional_edges`.\n",
        "\n",
        "Remember that **edges** route the control flow from one node to the next.\n",
        "\n",
        "**Conditional edges** usually contain \"if\" statements to route to different nodes depending on the current graph state.\n",
        "\n",
        "These functions receive the current graph `state` and return a string or list of strings indicating which node(s) to call next.\n",
        "\n",
        "Below, we will define a router function called `route_tools`, that checks for `tool_calls` in the chatbot's output.\n",
        "\n",
        "We provide this function to the graph by calling `add_conditional_edges`, which tells the graph that whenever the `chatbot` node completes to check this function to see where to go next.\n",
        "\n",
        "The condition will route to `tools` if tool calls are present and \"`__end__`\" if not.\n",
        "\n",
        "Later, we will replace this with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition) to be more concise, here we implement it from scratch to see what happens under the hood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KxYtA6jUon5y"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "def route_tools( state: State,) -> Literal[\"tools\", \"__end__\"]:\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    # if state is a list of messages get the last one\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    # if state is a dict, try to get the last message from the messages key\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    # if the last message is refering to a tool call, route to the tools node\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    # else route to end (stop the agent)\n",
        "    return \"__end__\"\n",
        "\n",
        "# The `tools_condition` function returns \"tools\"\n",
        "# if the chatbot asks to use a tool,\n",
        "# and \"__end__\" if it is fine directly responding and stopping the agent.\n",
        "# This conditional routing defines the main agent loop.\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    route_tools\n",
        ")\n",
        "\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "# set the entry point\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "# compile the graph\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Y0w9-jCZpj-Q",
        "outputId": "c23d046c-b41f-45b5-9e64-0843e2e2af28"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAD5ANgDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAUGBAcBAwgCCf/EAFQQAAEEAQICAwgNBwkECwAAAAEAAgMEBQYREiEHEzEUFRYiQVFWlAgXIzI2VWF0k7LR0tNCVHFzgZW0NThSdXaCkZKzRXLC1Bg0Q0RThZahscHh/8QAGwEBAAMBAQEBAAAAAAAAAAAAAAECAwQFBgf/xAAzEQEAAQIBCAgGAgMAAAAAAAAAAQIRAwQSITFBUVKRFBVhcaGxwdEFEyMzYpKB8CIy4f/aAAwDAQACEQMRAD8A/VNERAREQEREBdNm3BTj6yxNHAz+lI8NH+JUJfyF3NZCbGYmZ1OODxbeTaxrjE4jfq4g4Fpk22JLgWt3HJxOw4r9H2n45OunxkOStkDit5FvdMx/vP3I/QNh8i3iimnTiT/Ef3Qm29neFOFH+16HrLPtTwqwvxxQ9ZZ9qeC2FP8Asih6sz7E8FcL8T0PVmfYp+j2+CdB4VYX44oess+1PCrC/HFD1ln2p4K4X4noerM+xPBXC/E9D1Zn2J9Ht8DQeFWF+OKHrLPtTwqwvxxQ9ZZ9qeCuF+J6HqzPsTwVwvxPQ9WZ9ifR7fA0HhVhfjih6yz7Vm1b1a8wurWIrDR2uieHAf4LC8FcL8T0PVmfYsK3oDT1t4kGJr1bA3LbVJvc87Se0iSPhcOweXyJbBnbMcp9YRoWFFXK1u7pq3BTyVh+Qx9h7Yq2QewCSN55COfbYHiOwa8AAkhpHFsX2NZV0ZvbBMCIiogREQEREBERAREQEREBERAUZqfMjTunMplC0P7iqy2A0/lFrSQP27bKTUDrzHS5bRWcp1wXWJaUoiaBvu/hJaNv07LXCimcSmKtV4TGtlaZw/eHBVKTiHzsbxzyj/tZnEulkPyueXOP6VKLGxt+HK46rdrkmCzEyaMkbEtcAR/7FZKrXNU1TNWskURqvVuH0Pg58xnb0eOx0Ja100gJ3c5waxrWgEuc5xADWgkkgAFS61z094yllOj8syGDzecrQ3qtnbTZPfCo6OVr2WYQ3xnOjcA7haC4jfYHsVEIXWHsn9Jac0RkNRUBfzD6OQqY6xjW423DagksSNawyxOh6yIFpJaXMAeQGNJc5oM5qD2QGhdLWGV8plrNWx3LFemh7123vpwyNLmPstbETW3DXcpuAjhO+2xWh87T15qTou11TdDqTVmDpXcFbxF7NYM0szbbBfZNaiMAjjfKI2RtLXOja5xc4Di7VKdIAzuvdS63iyOL15LWyOLrt0hj8WL2NpyiSpvJ3bJCWCN7ZnvD2WXDZrQAxxOxDeGa6a9GYDUuO0/ay7pMxkYILVSpSpz2nTQzPeyORpiY4cBMbt3b7NABcQCCejob6YaHTNgshk6GPyGPjqZC1S4b1OxAJGxTyRMe10sTAS4R8TmN3MZdwO2cFqf2OuFynh1pPJ3MFlsdHU6MMXh5psnjZqpjtw2JRNAetY08QLQdvK3hcN2kE3f2M8F3B6Vz+nMnisljchjc/lJXvuU5IoLEc96xNFJBK4BsrSxzSS0nbcA7FBuBERBh5jFV85irePtNLq9mN0T9jsQCO0HyEdoI5ggFR+isrPmtLY+1bc11zgMNlzRsDNG4xyEDyDia5TT3tiY573BrGjcuJ2AHnVc6OI3N0dRne1zDcdNeDXt4XNE8r5gCPIdpBuF0RpwZvvjym/lCdiyoiLnQIiICIiAiIgIiICIiAiIgIiIKpBM3QcsleztHp2WR0sFsnxabnuLnRyf0Y9ySx3vRvwHh2ZxfOqOjjE61vQ5C3kc/Xe2ERNGI1FeoQubuXAmOvMxhd4x8YjcjYb7AbWxzQ9pa4BzSNiD2FVqTo+xsb3Ox09/C8R3MeNtvii/ZFuYx+xoXRnUYmmubTzv/AH+bp0TrQHtEaf3378a0/wDWuX/5pTek+jjGaNvS26N7P2pJY+qc3LagvZCMDcHcMsTPa13L3wAO2432JX0dE2CSfCnPD5BND+EngTY9Ks99ND+Eny8Pj8JLRvWhFV/Amx6VZ76aH8JVK3RysHSxitON1Tme99rCXMhITJF1nWxT1o27Hq+zaZ+427dk+Xh8fhJaN7aqrGrej3G6zsV5r13O1XwsLGjE567j2kE7+M2vKwOPyuBK48CbHpVnvpofwk8CbHpVnvpofwk+Xh8fhJaN6D9orT+23fjWe39tMv8A80pLTnRViNL5aLI1MjqWxPGHAR5LU2RuwncEHeKad7HdvLdvI8xzWV4E2PSrPfTQ/hLk9H2PtcsnayOaj3JMF+250Lt/I6JuzHD5HNITMw4118o97FodeRtx65EuKoPbPhyeryF1hJZI38qCJw5OJ968g7NBI99721NaGtDWgAAbADyL5hhjrxMiiY2ONjQ1rGDYNA7AB5AvtUrriYimnREAiIskCIiAiIgIiICIiAiIgIiICIiAiIgIiIC11kf5w2n/AOy2S/i6K2KtdZH+cNp/+y2S/i6KDYqIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAtd5Hb/AKQmn+R4vBfJbHfl/wBborYi11kf5w2n/wCy2S/i6KDYqIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIq9qDU89G63HYunHfyXViaQTymKGFhJDS94a47kg7NAO+x32HNRPf3WH5hg/W5vw1005PXVF9Ed8wmy7oqR391h+YYP1ub8NO/usPzDB+tzfhq/Ra98c4LLuvz+1L7PPL4j2R0GMn6K7B1FjYrWmu9keZDjNNNYrua9r+o977iNuXMPB8nP2V391h+YYP1ub8Nagy3QBNmPZDY3pcmx+G7806fUGp3RKYpZgOGOw4mPfjaw8I/Q0+Tm6LXvjnBZ6WRUjv7rD8wwfrc34ad/dYfmGD9bm/DTote+OcFl3RUjv7rD8wwfrc34ad/dYfmGD9bm/DTote+OcFl3RVvC6otTZGPHZenFSuTNc6vJWmMsM4b75oJa0teBseEjmNyCdnbWRc9eHVhzao1CIizQIiICIiAiIgIiICIiAiIgIiIKJDz19qX5Iqg/ZwP/AP1TCh4Ph9qb9XU+o9TC9avZ3U+ULTrERRDdV4p+rJdMttb5uOizIvq9W/lXdI6Nr+Lbh5uY4bb78uzZZqpdEWPcyNTHurttWoazrMoghE0gYZZCCQxu/a4gE7DnyPmUjIRROntV4rVRyYxdruo4y9Jjrfub2dXYj242eMBvtxDmNwd+RUsoBFjnI1BkBQNqEXjEZxV6wdaYwQ0v4e3h3IG/ZuVkKRCZo8OptGbdpysg328ncVpX5UHN/CbRf9bP/gbSvyyyrVR3esrTqgREXCqIiICIiAiIgIiICIiAiIgIiIKJB8PtTfq6n1HqYUPB8PtTfq6n1HqYXrV7O6nyharW0vqOrd6R+nLMaTt5/M4LEYfA1MhViwl99KWeeeadj5nPYQXtYIWtDDu3dxJBO21SoaSOtOnevRs6zyGSrs0FS67M4O33FJkHtvTgSdbA7do3BJaxwBJ58hstya46ItKdI12rczuNlnuVo3QR2al2epKYnHd0bnwvYXsJ58DiW/Is/C9HundOZeDJ4zFxUbcGMiw8Rgc5rI6cb3PjibHvwgBznHcDfntvssc3Sq86af1dqDXegOjbT7chncxqe4zKSSirmjiWWK1Sy6sJbVqON0wI3i2EQ3c4uLtwoKu/Ia9xXR9S1JkshYsYnpOu4IS0c7aLupZWsuDTYj6l0rmFjWtmc1r9g4cuN4d6Mn6CdEzYzEUG4merFiX2JKM1LI2q9iDr3l8wE0cjZOF7iSWl3CeQ22AXRJ7HvQL8dcoMwclalZuxZEwVchZgZDZjZwNlhDJB1DuE7ExcPEPfbqubI0RLirtbQXT7q2jqzL4fJaf1HlrtCKhcdDBHNDDHKBLGPFm6w7NLZOIbEbAHcm94nu/pk1lr2PL6hzem4cFVx8VGviMjLRbXdPSZYksSCNw608chaBJxMAi97vur1d9jxoDI3r9qxhJXuyNs3b0IyNpsF2UuDt54RL1coBG4a9paOewG5Ujq7oX0frnLyZTL4yWS9NXFSxJVvWKotQgkiOdsMjRMwcR8WQOHMqYpkaO6B79npA6XdH6uzMt4Zm50d1b8zW352QPmdO+Jz+pD+r4XNAdwcPCHEPA4vGXqdVo9G+nBqPCZ6PGNrZTDVXUaMtWWSFsdct26oxscGPYPI14IaQCNiAVZVamLCEzfwm0X/Wz/AOBtK/Kg5v4TaL/rZ/8AA2lflTKtVHd6ytOqBERcKoiIgIiICIiAiIgIiICIiAiIgokHw+1N+rqfUephY2fw2QpZiXMYqs3IGxEyGzSMojeeAu4Xxk+Lv4xBa7bcAHccOzoQanzDr/cjNHZeSYNc8lk1QsbsQNnP67hDvGGzSdyNyBsDt68WxIiYmNURpmI1RbbK06VkRQnfbP8AoZlPWqX46d9s/wChmU9apfjpmflH7R7lk2ihO+2f9DMp61S/HVYtdMden0g09DzYO9Hqq5UfegxxsVON8LSQXcXXcO/InhJ32BO2wTM/KP2j3LNhIoTvtn/QzKetUvx077Z/0MynrVL8dMz8o/aPcsm0UJ32z/oZlPWqX46d9s/6GZT1ql+OmZ+UftHuWM38JtF/1s/+BtK/KhaaFnU2dq3b9c4gY4ySQ4yw8d1OfvJCZXtHIR7cYaRxB3FxA7AcV9XJlNUTNNMTqj1mSdwiIuNUREQEREBERAREQEREBERAXDnBoJJAA5knyLEy+Yo4Gi65kbUVOsHsi6yV2wL3vDI2Dzuc9zWtaObnOAAJICizjbeo5XOy0RqY+OSzXOLL45or0Tvc2vmHD2FvGRHuRtI3i8YbNDgZK1qdwGJnNTGtdVssy0YjmjvRO90cyE8R5FvADJsRtIeHxhxNlsXiaWEpirj6sVOuHvl6uFgaC97y97z53Oe5znOPMucSSSSVlABoAA2A5ABcoCIiAvzv1h7Gbpwy/svK+s4dQ6Vr6hmMmbosN20YYqleWGIV3HucE7tmY3bbYjj3Pn/RBa6yP84bT/8AZbJfxdFBsVERAREQRmZwFfMMfIHOpZEV5a8GTrNZ3TWa/h4jG5zXAc2MdwkFpLG8QO2ywnagnwdh0WcjZDTdNWq1MjEXPFiSQcO0jQ33E9YOEbktPHHs7idwiwJ2oCKutw1vTfVnChsmMZ3TPPjHkvllkf47BDI94bGA8OHAfF2k5FgaAZLE5utmIWmImGyIo5Zqc2zZ6/G3ia2Rm+7TtvyPmPmQSCIiAiIgIiICIiAiIgKNzuoKmnoK77UjWPtTtq1mOO3Wzv34I9+wFxGwJ5b7KSVe1/ddi9HZTIjKjCR4+Lu6a+andXVQwkSS+5AEu3YxzfF8bnu3mAgyMPirXXMyeVkByctaKOWrBM59Wu4bl3VAgE7lxBeQC4NbybtsJlfEUrJo2SRuD43gOa5p3BB7CF9oCIiAiIgLXcw7u9kDQlrkTR47TduG45hB6iSazVdC1/mL2wykDzMJ8yktRanv5TLzaZ0u9nfWMN74ZN7A+HFMcA4AjsfO5pDmxeQEPfs0sEk5pjTFDSWLFKgx5DnmaaxM8vmsSu99LK883Pd5SfMANgAAEsiIgIiICIiAorM6fjyjZJYJ5MZkXCNoyFRrRMGsfxtYS4EOZvxAtPLZzuwndSqIIKnqN0Oabh8sK9TI2n2JMfHBI6TumtEY95Du0cLh1rAW8+fMEg8p1VzKZHqNdYCl33ZW7oqXZO9ZrcbrfAYPdBL+QI+PYt/K60f0VY0BERAREQEREBEULmNbae0/aFbJ5zHY+yRxdTZtMY/bz8JO+yvTRVXNqYvKbXTS+XtL2OaHFhI24m9o+Ubqse2lo70pxHrsf2qk9M1boz6b+jvK6Sz2pMMatxm8NgWonSVZh7yZm55OafNtuC5vYStej43BPKU5s7lk6NOkrTup6lbBV9aY3UuqcfWMWSijfHBcdJC4QzzSVAeKIGXtG2wLgAdiN72vzv8AYB9F1ToV6U+kLIasy+Lry0Y2YvHXO6mdRcY9/G+aFxPNuzI/lHEQdjuB7n9tLR3pTiPXY/tTo+NwTykzZ3LSiq3tpaO9KcR67H9qe2lo70pxHrsf2p0fG4J5SZs7lpVJzmosjqbK2dOaWsdyyQO6vKZ4MbIzHbgHqoQ4FslogghrgWRgh8gd4kUsZc11H0iZ2XTGlMzBBDExr8jl68rTK1jhv1dUflPI7Zdi1nYOJ+4besHg6Gm8VXxuMrMqUq7eGOJm523JJJJ5ucSSS4kkkkkkklY1UVUTaqLSrqdendOY/SmIhxuLr9z1Yi53jPdI+R7iXPkke4l0kjnEuc9xLnOcS4kklSaIqgiIgIiICIiAiIgrmUyPUa6wFLvuyt3RUuyd6zW43W+Awe6CX8gR8exb+V1o/oqxrVOoen3o7w+vKVC30qaVxjqjLkF7FWL9fj69romgSSF/uDoyHjq3bFxceXiHbZ9C/WylGvdpWIrdOzG2aGxA8PjlY4btc1w5FpBBBHIgoO9ERAREQEREGFmrjsfh71pgBfBBJK0HztaSP/hVHSVSOtgKUgHFPZiZPPM7m+aRzQXPcTzJJP7OzsCs+qvgxmPmc31Cq9pr4OYr5pF9QL0MDRhT3p2JJERXQIiICIiCD1rC06ayFtvudulBJarTtHjwysYS1zTy82xG/MEg8iVeKNg26VecjhMsbXkDybjdUrWnwOzvzCf/AE3K4Yb+R6P6iP6oVMf7VM9s+idjMREXnoEREBEVN6R9fDR1KGvUayfL2w7qI3+9iaO2V48rQSAAObiQOQ3I2wcKvHrjDw4vMixZjUGM09XbPlMhVx8TjwtdZlbGHHzDc8z8gVbf0y6NY7bv5E75WxSOH+IatGTmS7ekvXZ5L1+T39qwQ57vkHIBo5nxWgAb8gFyvrMP4HhRT9SuZns0edy8N4e3Poz46Z9BL9xPbn0Z8dM+gl+4tHoteo8m4qucexeGg+m32O+lNe+y3w2o6N5g0NmpBkM9I2KRohmj5yM224vdtm7Eb+M955AL3VD0w6Jrwsiiy8UUTGhrGMrShrQOQAHByC0iidR5NxVc49i8N4e3Poz46Z9BL9xct6ZdGuOwzbP2wSj/AIVo5E6jybiq5x7F4ejcFrHB6mc5uKy1S9IwbuihlBkaPOW9o/aFMryrLWjlkjkILJozxRzRuLJIz52vGzmn5QQtu9F/SNNk7DMFmJRJe4Satt2wNkAElrh/TaBvuPfAE9oO/lZb8JqyeicXCm8Rr3x7midTZqIi+dEXqr4MZj5nN9Qqvaa+DmK+aRfUCsOqvgxmPmc31Cq9pr4OYr5pF9QL0cH7M9/onYzLr7DKc7qkUU9oRuMMU0hjY9+3ihzw1xaCdtyGnbt2PYtCdGvTxqrJdGujLGTwlPMav1TbsxYyrXyHVRSRRF75JZ39QBC2NreHZrZC7xO0uIb6BXnnTXQdrfSeC0Uac+AnzOir1xuOEtmdsGRo2WuD2zOERdBL4zCC0SAFnl4thE3voQsknshJKNTI4+/pp8Otqmar4JmBguiSKeexF10L22Cxo6oxB7y4sDmiN44SQAav0u9L2dPR30g4S7Sfo/WGGrUbsb8Xk3TslrTWWsbLDOGRO98yRjgWtI+UFZuQ6CNU5ae/q2e/h4deSaip56tWjMrsfEytXNZlZ0haJHB0UkxMnAPGeCGbN58aw6D9XdIlDXOTzE+EpakzuPo4mlTqWJpalStXsGc8czomve57nvPKMAbNHnKr/kLHY6b8pd1pqHCae0pHnI9P246l9hy8Ve+8ujjkc+Cq5vujGtlHjOeziIIbvsttrQPS30I6q6TMpk4ZKGkC2SUOxOrCZ6+Yw7Nh7xscZ61zSN2nrmA8t28ue/WNLWNBcXEDYuPaflV4vtEPrT4HZ35hP/puVww38j0f1Ef1QqfrT4HZ35hP/puVww38j0f1Ef1Qox/s098+UJ2MxEReegREQF5v1rknZjXufsvcXCGcUogfyGRNAIH98yO/vL0gvN+tsa7Da9z9Z7eFs84uxE/lskaCT/nEg/ur6P4Hm/Pqvrt6wnZKJRYWYzeO09Rfdyt+rjKbCGusXJmxRgk7AFziBzKgB0uaFPZrTTx/81g++vsqq6KZtVMQzWxayxvTLNdo0M7NgHVtI5C62lWyndYdMeOTqo5nw8OzY3P2APGT4wJaArHH0saHsSNij1jp+SR5DWsblICXE9gA4ua1xp32PUGmrOLpwad0nbp07QlOatwPdefEH8TW9WGhvWAbN6zrPJvweRcuLiVzMfJm8bfC2/t3d6U7kumjI0qOqcnHpgS4bTd6WpesuyHBI9sfCS+GPqzxkNduWuc0eQOcd9pHUXSLfkyGpcbhMOb8OFqNfeui2IZGPkiMjWws4TxuDC13NzB4wAJKwsl0XZW5oDpFwbLFMW9R3bdmo9z39WxsrGBokPDuCOE77A/tXOQ0HqrHZvVM2BnxTqmpIIWzSXZJGyUpmQiF0jGtYRKCxrTwlzOY7SOSymceNd+Ufl/wWLoju2Ml0V6Pt3LEtq1PiKsss87y98jzE0lznHmSTzJKtq15pDVGmujnSOC0vnNWYCpl8RQr07UL8lEwteyJoPJ5a7Y9o3AOxHJS/tu6E9NdO/vWD766cPEopopiqqL23oWxdNrIyYRseVh3E2Okbcbt2ngPER+1oLT8hKwcFqnC6pilkwuXoZeOIhsj6Flk4YT2AlpOx/Ss61jZM42PEwgmbIyNpt27Rxnhcf2NLnH5Glb3oqpvP+votTrh6rBBAIO4PlCIAAAANgPIi/KUozVXwYzHzOb6hVe018HMV80i+oFaczTdkcReqMID54JIgT5C5pH/ANqoaSuR2MDThB4LNaFkFiB3J8MjWgOY4HmCD/iNiORC9DA04Ux2p2JhERXQIiICIiCG1p8Ds78wn/03K4Yb+R6P6iP6oVL1pOzwcv0m7SXL0ElWrXafHmlewhrWjmflJ22ABJ5Aq80q5qUq8BPEYo2s38+w2VMfRhUx2z6J2O9EReegREQFTukfQQ1jRinqvZBl6nEYJH+8kaffRPPaGkgHcc2kA7EbtdcUW2Di14FcYmHNpgeV7kTqlx+PyNZ9K6z39S00B36R2hw5Hxmkg7cius0ax/7vF/kC9O5fBY3P1xBk6FbIQg7hlmJsgafONxyPyhVt3Q7o1537wwN+Rj3tH+AdsvrMP45hTH1aJiezT52LQ0MKVcHcQRb/AO4F3LeXtN6N+I4vpZPvJ7TejfiOL6WT7y167ybhq5R7loaNRby9pvRvxHF9LJ95Pab0b8RxfSyfeTrzJuGrlHuWhol9WGRxc+GNzj2lzQSvnuKv/wCBF/kC3x7TejfiOL6WT7y5HQ5o1p37xxH9Mkh/4lHXeTcNXKPctDQnWV6sjIY2Dr5TtHXgYXSynzNY0Fzj8gBW4ui/o5mxM7c5mIxHfLSK1Q7E1mkbOc4jcF7hy5dg3HPcq64PSOE0zxnFYmnj3vGz314Wte//AHnbbn9pUuvKy34tVlFE4WFGbE698+ydEahERfPIFC5jRen9Q2BYymDx2RsAcIltVI5HgebdwJ2U0itTXVRN6ZtJqVb2rNGeieF/d8X3U9qzRnonhf3fF91WlFt0jG455ym871W9qzRnonhf3fF91Pas0Z6J4X93xfdVpROkY3HPOS871W9qzRnonhf3fF91Pas0Z6J4X93xfdVpROkY3HPOS870Rh9H4LT0zpcXhcfjpXN4TJVqsjcR5t2gHb5FLoixqqqrm9U3lAiIqgiIgIiICIiAiIgIiICIiAiIgIiIP//Z\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFjfwed3tbPd"
      },
      "source": [
        "Let's test out our agent now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "ytZmTFzOtpbU",
        "outputId": "bb8ef612-9103-4117-816e-2b0f29f0483e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The fastest land animal is the cheetah. It can reach speeds of up to 60 to 70 miles per hour (97 to 113 kilometers per hour) in short bursts covering distances up to 1,500 feet (460 meters), and it can accelerate from 0 to 60 miles per hour in just a few seconds."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"What is the fastest animal on land?\"\"\"\n",
        "response = graph.invoke({\"messages\": (\"user\", prompt)})\n",
        "display(Markdown(response['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nywuf9pBuVQK",
        "outputId": "d05ad410-cd80-449d-8be2-485f8d18e59e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is the fastest animal on land?', id='fae9b595-a054-43d6-bcc7-0d8d078e37b0'),\n",
              "  AIMessage(content='The fastest land animal is the cheetah. It can reach speeds of up to 60 to 70 miles per hour (97 to 113 kilometers per hour) in short bursts covering distances up to 1,500 feet (460 meters), and it can accelerate from 0 to 60 miles per hour in just a few seconds.', response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 75, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-e72e59f4-30ae-4c45-a89d-94bc9c1ff3db-0')]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "1nMNNs7DuXEJ",
        "outputId": "2f3b1e32-bb5a-4096-f222-c6fb53b2328a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Langraph is an advanced, scalable solution for building AI systems that require both information retrieval and language generation. It integrates techniques like Retrieval-Augmented Generation (RAG) to improve the quality of responses while scaling for large datasets. Langraph is designed to bridge the gap between traditional rule-based systems and modern, data-driven approaches like Large Language Models (LLMs). It enables the development of advanced AI agents capable of understanding, processing, and generating human language in a structured, meaningful way.\n\nLangraph is part of the LangChain ecosystem and provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. This makes it suitable for applications requiring autonomous decision-making, such as automated customer support, data processing, and system monitoring."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"What is langraph?\"\"\"\n",
        "response = graph.invoke({\"messages\": (\"user\", prompt)})\n",
        "display(Markdown(response['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En8vFPfUuacc",
        "outputId": "b3e314da-a5c9-4fd6-ba93-5a4974dcd298"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is langraph?', id='b8e6e110-364c-4627-8a6d-bbf157b4de1f'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NSMVNSX8JKOfKjpD52dsWz3e', 'function': {'arguments': '{\"query\":\"langraph\"}', 'name': 'search_web'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 72, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-661db01c-ec56-4aaf-b88a-8290d03d41ce-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'langraph'}, 'id': 'call_NSMVNSX8JKOfKjpD52dsWz3e', 'type': 'tool_call'}]),\n",
              "  ToolMessage(content='[{\"url\": \"https://medium.com/@jagadeesan.ganesh/a-comprehensive-guide-to-langraph-step-by-step-with-examples-56ab31a987ee\", \"content\": \"Langraph is an advanced, scalable solution for building AI systems that require both information retrieval and language generation. By integrating RAG techniques, Langraph improves the quality of responses while scaling for large datasets. Whether you\\\\u2019re building a chatbot, a virtual assistant, or a large-scale search engine, Langraph can help you achieve high-performance results. [...] What is Langraph?\\\\n\\\\nLangraph enables the development of advanced AI agents capable of understanding, processing, and generating human language in a structured, meaningful way. It\\\\u2019s designed to bridge the gap between traditional rule-based systems and modern, data-driven approaches like Large Language Models (LLMs).\\\\n\\\\nKey Concepts of Langraph\\\\n\\\\nWhy Langraph?\\\\n\\\\nStep-by-Step Guide to Implementing Langraph\\\\n\\\\nStep 1: Installing Required Libraries [...] Sign up\\\\n\\\\nSign in\\\\n\\\\nSign up\\\\n\\\\nSign in\\\\n\\\\n--\\\\n\\\\nListen\\\\n\\\\nShare\\\\n\\\\nA Comprehensive Guide to Langraph: Step-by-Step with Examples\\\\n\\\\nLangraph is an emerging technology in the world of natural language processing (NLP), focusing on simplifying complex interactions between humans and AI agents. This guide will take you through the process of understanding Langraph and applying it to real-world use cases. We will cover its core components, implementation, and advanced techniques with hands-on examples.\"}, {\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\\\nLLM applications: By using LangGraph\\\\u2019s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.\"}, {\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems. [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring. [...] Home\\\\nTutorials\\\\n\\\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\\\nContents\\\\nJun 26, 2024 \\\\u00a0\\\\u00b7 12 min read\\\\nContents\\\\n\\\\nWhat Is LangGraph?\\\\nGraph structure\\\\nState management\\\\n\\\\nCoordination\\\\n\\\\n\\\\nWhy LangGraph?\\\\n\\\\nSimplified development\\\\nFlexibility\\\\nScalability\\\\n\\\\nFault tolerance\\\\n\\\\n\\\\nGetting Started With LangGraph\"}]', name='search_web', id='89a4ed13-a1b8-451c-ab95-7cc6990c908f', tool_call_id='call_NSMVNSX8JKOfKjpD52dsWz3e'),\n",
              "  AIMessage(content='Langraph is an advanced, scalable solution for building AI systems that require both information retrieval and language generation. It integrates techniques like Retrieval-Augmented Generation (RAG) to improve the quality of responses while scaling for large datasets. Langraph is designed to bridge the gap between traditional rule-based systems and modern, data-driven approaches like Large Language Models (LLMs). It enables the development of advanced AI agents capable of understanding, processing, and generating human language in a structured, meaningful way.\\n\\nLangraph is part of the LangChain ecosystem and provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. This makes it suitable for applications requiring autonomous decision-making, such as automated customer support, data processing, and system monitoring.', response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 993, 'total_tokens': 1171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-37b596eb-f97c-4a41-8ecb-f335ce2edcda-0')]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPcJl2m-vYMZ"
      },
      "source": [
        "### Build the Agentic Graph with LangGraph built-ins\n",
        "\n",
        "Here we will use LangGraph to build the full graph which will have the Agentic workflow.\n",
        "\n",
        "Each functionality will be implemented as we would in the real-world.\n",
        "\n",
        "Here we will be replacing our `BasicToolNode` for the prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode),\n",
        "and our `route_tools` condition with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "akYszF3ivXiS"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "# define function which will be used to store all agent messages\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# start the graph building\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# add tools and bind to LLM\n",
        "tools = [search_web, get_weather]\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# add the LLM to graph\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Add tools to a node\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# add conditional edges\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        "    {'tools': 'tools', '__end__': '__end__'}\n",
        ")\n",
        "\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "# Define entry point to the graph\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "# compile the graph\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "rdBRSLehwMm_",
        "outputId": "8b345cdd-f08f-4881-c136-6e77b62bd4bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "2UgxjeIrwN1h",
        "outputId": "ddfc7509-7421-4046-c637-34580c9edb51"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current weather in Bangalore, Karnataka, India is as follows:\n\n- **Temperature**: 27.4°C (81.3°F)\n- **Condition**: Partly cloudy\n- **Wind**: 16.8 mph (27.0 kph) from the west-southwest (WSW) at 248°\n- **Pressure**: 1008.0 mb (29.77 in)\n- **Precipitation**: 0.02 mm (0.0 in)\n- **Humidity**: 79%\n- **Cloud Cover**: 75%\n- **Feels Like**: 32.3°C (90.1°F)\n- **Wind Chill**: 20.8°C (69.4°F)\n- **Heat Index**: 20.8°C (69.4°F)\n- **Dew Point**: 18.8°C (65.8°F)\n- **Visibility**: 6.0 km (3.0 miles)\n- **UV Index**: 2.1\n- **Wind Gusts**: 22.7 mph (36.5 kph)\n\nThe local time in Bangalore is 15:08 on May 30, 2025."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"What is the weather in bangalore?\n",
        "show detailed statistics\"\"\"\n",
        "response = graph.invoke({\"messages\": (\"user\", prompt)})\n",
        "display(Markdown(response['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "hLqZiU6exnN5",
        "outputId": "d246ccff-2c1e-4721-c0fc-853542065087"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current weather in Dubai is sunny. Here are the detailed statistics:\n\n- **Temperature**: 40.3°C (104.5°F)\n- **Feels Like**: 42.3°C (108.1°F)\n- **Condition**: Sunny ![Sunny Icon](https://cdn.weatherapi.com/weather/64x64/day/113.png)\n- **Wind**: 13.6 mph (22.0 kph) from the west (273°)\n- **Wind Gusts**: Up to 28.7 mph (46.1 kph)\n- **Humidity**: 32%\n- **Pressure**: 999.0 mb (29.5 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Cloud Cover**: 0%\n- **Visibility**: 10.0 km (6.0 miles)\n- **UV Index**: 11.1 (Very High)\n- **Dew Point**: 22.2°C (71.9°F)\n\nThe weather is quite hot and sunny, with a high UV index, so it's advisable to take precautions if you're planning to be outdoors."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"What is the weather in dubai? show detailed statistics\"\"\"\n",
        "response = graph.invoke({\"messages\": (\"user\", prompt)})\n",
        "display(Markdown(response['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "2JRHxzdPxo8A",
        "outputId": "d73d7b1c-f6dd-40d5-c936-ee45ec28dd7d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To determine which city is hotter, I need to know the names of the cities you're interested in comparing. Could you please provide those?"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"Which city is hotter?\"\"\"\n",
        "response = graph.invoke({\"messages\": (\"user\", prompt)})\n",
        "display(Markdown(response['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtXAlOdBxt-j"
      },
      "source": [
        "We have successfully built an AI Agent which can search the web, get weather for us but it is not yet conversational. We will add in the that functionality in Part III next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcfps7EJy570"
      },
      "source": [
        "## Part III: Build a multi-user conversational ReAct Agent with LangGraph\n",
        "\n",
        "Now, we will build a multi-user conversational ReAct agent with LangGraph which will use the web search or weather tool based on our input prompts to get relevant data which the LLM might not know by default and give relevant responses\n",
        "\n",
        "Our agentic chatbot from Part II can use tools to answer user questions, but it doesn't remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\n",
        "\n",
        "LangGraph solves this problem through **persistent checkpointing**. If you provide a `checkpointer` when compiling the graph and a `thread_id` when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same `thread_id`, the graph loads its saved state, allowing the chatbot to pick up where it left off.\n",
        "\n",
        "**checkpointing** is _much_ more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more\n",
        "\n",
        "While the legacy syntax uses `session_id`, in LangGraph, each user session is identified by `thread_id`\n",
        "\n",
        "We will use `SqliteSaver` which helps to store separate conversation histories per user or session.\n",
        "\n",
        "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cph9LvyvIRrA",
        "outputId": "65d0a457-667a-41cc-9da9-b15c6a9d0bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'memory.db*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# removes the memory database file - usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
        "!rm memory.db*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qzwnf7vfzTiI"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "# used to retrieve conversation history from database\n",
        "# based on a specific user or session ID  - thread_id\n",
        "memory = SqliteSaver.from_conn_string(\"memory.db\")\n",
        "\n",
        "# define function which will be used to store all agent messages\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# start the graph building\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# add tools and bind to LLM\n",
        "tools = [search_web, get_weather]\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# add the LLM to graph\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Add tools to a node\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# add conditional edges\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        "    # either goes to tool node if tool calls or else end node\n",
        "    {'tools': 'tools', '__end__': '__end__'}\n",
        ")\n",
        "\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "# Define entry point to the graph\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "# compile the graph - Add the memory here\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "d8jgYAwTIptc",
        "outputId": "7cbdefd5-d0fe-4171-970c-009f55d0055e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "w2suIezLJK1S"
      },
      "outputs": [],
      "source": [
        "def chat_with_agent(prompt: str, session_id: str):\n",
        "    response = graph.invoke({\"messages\": [('user', prompt)]},\n",
        "                                      {'configurable': { 'thread_id': session_id}})\n",
        "    display(Markdown(response['messages'][-1].content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYTNL_iJ6ibC"
      },
      "source": [
        "Let's now simulate User 1 using the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "irMU68Ds0NTm",
        "outputId": "01151cc5-7677-4ed9-d8ba-bf94cda468dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Langraph is an advanced framework designed for building AI systems that require both information retrieval and language generation. It integrates Retrieval-Augmented Generation (RAG) techniques to enhance the quality of responses and is scalable for large datasets. Langraph is particularly useful for developing chatbots, virtual assistants, and large-scale search engines.\n\nKey features of Langraph include:\n\n1. **AI Agent Framework**: Langraph provides a framework for creating, deploying, and managing complex generative AI agent workflows. It uses graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow.\n\n2. **Scalability and Efficiency**: It allows users to create, run, and optimize large language models (LLMs) efficiently. The graph-based architecture enables scaling of AI workflows without compromising on speed or efficiency.\n\n3. **Stateful Orchestration**: Langraph offers a stateful orchestration framework that provides added control to agent workflows. This includes a platform for deploying and scaling applications with an opinionated API for building agent user experiences.\n\n4. **Applications**: Langraph is used in various applications, including robotics, autonomous vehicles, and video games. It also supports the development of sophisticated AI models that learn and improve over time.\n\n5. **Developer Tools**: Langraph provides SDKs in Python and JavaScript, along with a developer studio for building and deploying applications.\n\nOverall, Langraph is a powerful tool for developers looking to build reliable and scalable AI agents across different industries."
          },
          "metadata": {}
        }
      ],
      "source": [
        "user_id = 'jack001'\n",
        "prompt = \"Tell me about langraph\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "XT4vtvku0TBW",
        "outputId": "d5049e79-b5f0-465d-8e36-478dfbf2b9be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Langraph is used for developing advanced AI systems and applications that require complex interactions between humans and AI agents. Here are some specific use cases:\n\n1. **Chatbots and Virtual Assistants**: Langraph can be used to build intelligent chatbots and virtual assistants that understand, process, and generate human language in a meaningful way.\n\n2. **Large-Scale Search Engines**: It helps in creating search engines that can efficiently retrieve and generate information from large datasets.\n\n3. **Agent-Based Systems**: Langraph provides a framework for building agent-based systems used in applications such as robotics, autonomous vehicles, and video games.\n\n4. **Generative AI Workflows**: It is used to create, deploy, and manage complex generative AI workflows, allowing for the development of sophisticated AI models that can learn and improve over time.\n\n5. **Personalized User Experiences**: By leveraging its capabilities, Langraph can be used to develop AI solutions that offer improved and personalized experiences, such as those used in customer service or hospitality industries.\n\n6. **Scalable AI Applications**: Langraph's graph-based architecture allows for the scaling of AI workflows, making it suitable for applications that require high performance and efficiency.\n\nOverall, Langraph is a versatile tool for developers aiming to build reliable, scalable, and intelligent AI agents across various industries."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"What is it used for?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4zIlISy6m-x"
      },
      "source": [
        "Let's now simulate User 2 using the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "ta1RUF_81RxX",
        "outputId": "7b69869d-b84c-4a0c-89c4-d77f836c67de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current weather in Bangalore is as follows:\n\n- **Temperature**: 27.4°C (81.3°F)\n- **Condition**: Partly cloudy ![Partly cloudy](https://cdn.weatherapi.com/weather/64x64/day/116.png)\n- **Feels Like**: 32.3°C (90.1°F)\n- **Wind**: 16.8 mph (27.0 kph) from the WSW (248°)\n- **Gusts**: Up to 22.7 mph (36.5 kph)\n- **Pressure**: 1008.0 mb (29.77 in)\n- **Precipitation**: 0.02 mm\n- **Humidity**: 79%\n- **Cloud Cover**: 75%\n- **Visibility**: 6.0 km (3.0 miles)\n- **UV Index**: 2.1\n- **Dew Point**: 18.8°C (65.8°F)\n\nThe weather is partly cloudy with a moderate breeze from the west-southwest."
          },
          "metadata": {}
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"how is the weather in Bangalore today? Show detailed statistics\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "vfn_Wxxg42rZ",
        "outputId": "9a3ea61c-029c-4860-9a27-e3286af4314e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current weather in Dubai is as follows:\n\n- **Temperature**: 40.3°C (104.5°F)\n- **Condition**: Sunny ![Sunny](https://cdn.weatherapi.com/weather/64x64/day/113.png)\n- **Feels Like**: 42.3°C (108.1°F)\n- **Wind**: 13.6 mph (22.0 kph) from the W (273°)\n- **Gusts**: Up to 28.7 mph (46.1 kph)\n- **Pressure**: 999.0 mb (29.5 in)\n- **Precipitation**: 0.0 mm\n- **Humidity**: 32%\n- **Cloud Cover**: 0%\n- **Visibility**: 10.0 km (6.0 miles)\n- **UV Index**: 11.1\n- **Dew Point**: 22.2°C (71.9°F)\n\nThe weather is sunny with a warm breeze from the west. The UV index is very high, so sun protection is recommended."
          },
          "metadata": {}
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"what about Dubai?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "I7jjxtmz6Qzi",
        "outputId": "e35e30bb-73c6-43a3-f5c1-73ddc22133c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Dubai is hotter than Bangalore. The current temperature in Dubai is 40.3°C (104.5°F), while in Bangalore, it is 27.4°C (81.3°F)."
          },
          "metadata": {}
        }
      ],
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"which city is hotter?\"\n",
        "chat_with_agent(prompt, user_id)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}